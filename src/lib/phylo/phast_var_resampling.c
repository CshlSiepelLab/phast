/* experimental resampling routines for refining samples from
   variational distribution.  Some of this code is generated by
   chatGPT */

#include <stdio.h>
#include <stdlib.h>
#include <ctype.h>
#include <assert.h>
#include <float.h>
#include "phast/misc.h"
#include "phast/nj.h"
#include "phast/mvn.h"
#include "phast/multi_mvn.h"
#include "phast/trees.h"

/* subsample from a set of trees by importance sampling, using ratio
   of likelihoods to sampling density as weights.  Warning: tree
   objects in returned list will be shared with those in primary list
   and may repeat */
List *nj_importance_sample(int nsamples, List *trees, Vector *logdens,
                           TreeModel *mod, CovarData *data, FILE *logf) {
  List *retval = lst_new_ptr(nsamples);
  Vector *weights = vec_new(lst_size(trees));
  Vector *lls = vec_new(lst_size(trees));
  double ll, maxll = -INFTY, maxweight = -INFTY, sampll = 0;
  int i, count = 0;

  if (logdens->size != lst_size(trees))
    die("ERROR in nj_importance_sample: bad input.\n");
  
  /* calculate importance weights from likelihoods */
  for (i = 0; i < lst_size(trees); i++) {
    TreeNode *t = lst_get_ptr(trees, i);    
    mod->tree = t;
    ll = nj_compute_log_likelihood(mod, data, NULL);
    if (!isfinite(ll))  /* can happen with crispr model */
      ll = -INFTY;
    if (ll > maxll) maxll = ll;
    vec_set(lls, i, ll);
    ll -= vec_get(logdens, i);
    vec_set(weights, i, ll);
    if (ll > maxweight) maxweight = ll;
  }
  assert(maxweight > -INFTY);

  /* exponentiate and renormalize */
  for (i = 0; i < lst_size(trees); i++) {
    ll = vec_get(weights,i);
    vec_set(weights, i, exp(ll-maxweight));  /* avoids underflow */
  }
  pv_normalize(weights);

  for (i = 0; i < lst_size(trees); i++) 
    if (vec_get(weights, i) > 1.0/(lst_size(trees)*10))
      count++;

  if (count < nsamples)
    fprintf(stderr, "Warning: only %d trees eligible for importance sampling...\n", count);
    
  /* now draw nsamples */
  for (i = 0; i < nsamples; i++) {
    int j = pv_draw_idx(weights);
    assert(j >= 0 && j < lst_size(trees));
    lst_push_ptr(retval, lst_get_ptr(trees, j));
    sampll += vec_get(lls, j);
  }

  if (logf != NULL)
    fprintf(logf, "# Importance sampling from %d eligible trees of %d; avelnl: %f, maxlnl: %f\n",
            count, lst_size(trees), sampll/nsamples, maxll);

  vec_free(weights);
  vec_free(lls);
  
  return(retval);
}

/* for use below -- looks up region corresponding given value of z^2 using binary search */
static inline int get_region(Vector *quants, double z2) {
    int lo = 0, hi = quants->size - 1; 
    while (lo + 1 < hi) {
        int mid = (lo + hi) >> 1;
        if (z2 < vec_get(quants, mid))
          hi = mid;
        else
          lo = mid;
    }
    return lo; 
}

/* Like nj_var_sample, but use rejection sampling to sharpen the
   approximate posterior.  Divides sampling distribution into regions
   ("shells") based on distance from mean. Recalibrates region by
   region if envelope violations occur.  Has a number of other
   optimizations to improve acceptance rate and efficiency, but
   overall rate still tends to be low in many cases. */
List *nj_var_sample_rejection(int nsamples, multi_MVN *mmvn,
                              CovarData *data, TreeModel *mod,
                              FILE *logf) {
  int nprop = max(nsamples * 10, 2000);
  int dim = mmvn->d * mmvn->n;
  int nreg = 12; /* number of regions into which to partition sampling space */
  const double q_center = 0.990; /* inner shells */
  const double q_tail   = 0.9990;/* outer shells */
  const double m_center = 0.35;  /* inner shells margin */
  const double m_tail   = 0.60;  /* outer shells margin */
  const double delta_min = 0.25;   /* minimum bump on violation (log-space) */
  const double tail_frac = 0.20;  /* top fraction used to estimate tail spread */
  const int    tail_nmin = 20;    /* minimum tail sample size per region */
  const double gap_gain  = 1.05;  /* scales observed gap in bump */
  const double bump_gain = 1.60;  /* geometric escalation per repeated violation */
  List *retval = lst_new_ptr(nsamples), *init_samples = lst_new_ptr(nprop);
  Vector *points_x = vec_new(dim), *points_z = vec_new(dim),
    *points_y = vec_new(dim), *quants;
  double lnl, mvnl, logu, z2, avelnl = 0, logdet;
  double *ll, *mvnll, *logM, *sigma_tail;
  int i, ntot, r;
  int *reg, *regnum, *accpt;
  unsigned int *retained;
  int *viol_count;
  int *since_viol;    /* proposals since last violation in this region */
  const int cooldown_trigger = 200;  /* proposals (any shells) between decays */
  const int cooldown_step = 1;    /* how much to reduce viol_count on cooldown */
 
  /* per-accepted-sample metadata for region-specific revalidation */
  int    *acc_region = smalloc(nsamples * sizeof(int));
  double *acc_logu = smalloc(nsamples * sizeof(double));
  double *acc_logr = smalloc(nsamples * sizeof(double));
  double *acc_ll = smalloc(nsamples * sizeof(double));  /* for avelnl repair */
  
  ll = smalloc(nprop * sizeof(double));
  mvnll = smalloc(nprop * sizeof(double));
  logM = smalloc(nreg * sizeof(double));
  sigma_tail = smalloc(nreg * sizeof(double));
  reg = smalloc(nprop * sizeof(int));
  retained = smalloc(nprop * sizeof(unsigned int));
  regnum = smalloc(nreg * sizeof(int));
  accpt = smalloc(nreg * sizeof(int));
  viol_count = smalloc(nreg * sizeof(int));
  since_viol = smalloc(nreg * sizeof(int));
  
  for (r = 0; r < nreg; r++) {
    logM[r] = -INFTY; regnum[r] = 0; accpt[r] = 0;
    viol_count[r] = 0; since_viol[r] = 0;
  }
  
  /* preprocessing step to partition sampling space into equally sized
     regions, with one bound per region.  Use the fact that the
     initial standard MVN variable z is such that z^2 is chisq
     distributed with d d.o.f.  We can therefore partition based on
     the quantiles of the chisq distribution */

  quants = vec_new(nreg+1);
  vec_set(quants, 0, 0);
  for (r = 1; r < nreg; r++)
    vec_set(quants, r, chisq_cdf_inv((double)r / nreg, dim));
  vec_set(quants, nreg, INFINITY);
  /* ith quantile ranges from quants[i] to quants[i+1], with i ranging from 0 to nreg-1 */

 
  /* collect an initial sample to approximate the upper bounds on the
     log ratio of densities */
  for (i = 0; i < nprop; i++) {
    do {
      nj_sample_points(mmvn, points_x, points_z);
      nj_apply_normalizing_flows(points_y, points_x, data, &logdet);
      nj_points_to_distances(points_y, data);
      mod->tree = nj_inf(data->dist, data->names, NULL, data);

      if (data->crispr_mod != NULL)
        ll[i] = cpr_compute_log_likelihood(data->crispr_mod, NULL);
      else
        ll[i] = nj_compute_log_likelihood(mod, data, NULL);

      if (!isfinite(ll[i]) || !isfinite(logdet)) tr_free(mod->tree);
    } while (!isfinite(ll[i]) || !isfinite(logdet));  
    
    lst_push_ptr(init_samples, mod->tree);
    mvnll[i] = mmvn_log_dens(mmvn, points_x) - logdet;   /* note logdet jacobian for flows */

    /* find region corresponding to quantile */
    z2 = vec_inner_prod(points_z, points_z);
    reg[i] = get_region(quants, z2);
    regnum[reg[i]]++;      
  }

 /* set per-region envelopes from pilot quantiles */
  List *tmp = lst_new_dbl(nprop);
  for (r = 0; r < nreg; r++) {
    lst_clear(tmp);
    if (regnum[r] <= 0) { logM[r] = -INFTY; continue; }  /* safety: should not happen */
    for (i = 0; i < nprop; i++) if (reg[i] == r) lst_push_dbl(tmp, ll[i] - mvnll[i]);
    lst_qsort_dbl(tmp, ASCENDING);
    int m = lst_size(tmp);
    double t = (double)r / (double)(nreg - 1);               /* 0..1 from inner->outer */
    double q_r = q_center + t * (q_tail - q_center);         /* interpolate quantile */
    double mg  = m_center + t * (m_tail - m_center);         /* interpolate margin  */
    if (q_r > 0.9999) q_r = 0.9999;                          /* clamp */
    int idx = (int) floor(q_r * (double)(m - 1));
    logM[r] = lst_get_dbl(tmp, idx) + mg;   /* per-shell quantile + margin */
    /* estimate tail spread sigma_tail[r] from top tail_frac (>= tail_nmin) */
    int tail_n = (int) (tail_frac * m);
    if (tail_n < tail_nmin) tail_n = tail_nmin;
    if (tail_n > m) tail_n = m;
    /* compute unbiased SD over the top tail_n values */
    double mean = 0.0, var = 0.0, x;
    for (i = m - tail_n; i < m; i++) { x = lst_get_dbl(tmp, i); mean += x; }
    mean /= (double)tail_n;
    for (i = m - tail_n; i < m; i++) { x = lst_get_dbl(tmp, i); double d = x - mean; var += d*d; }
    sigma_tail[r] = (tail_n > 1) ? sqrt(var / (double)(tail_n - 1)) : 0.0;
  }
  lst_free(tmp);

  /* light smoothing: enforce nondecreasing logM and sigma_tail across shells */
  for (r = 1; r < nreg; ++r) {
    if (logM[r] < logM[r-1]) logM[r] = logM[r-1];
    if (sigma_tail[r] < sigma_tail[r-1]) sigma_tail[r] = sigma_tail[r-1];
  }
  
  /* subsample from initial set by rejection sampling */

  for (i = 0; i < lst_size(init_samples); i++)
    retained[i] = FALSE; /* init */
    
  for (i = 0; i < lst_size(init_samples) &&
         lst_size(retval) < nsamples; i++) {
    logu = log(unif_rand());
    if (logu <= ll[i] - mvnll[i] - logM[reg[i]]) {
      int idx = lst_size(retval);
      lst_push_ptr(retval, lst_get_ptr(init_samples, i));
      retained[i] = TRUE;
      avelnl += ll[i];

      /* record acceptance metadata for region-specific revalidation */
      acc_region[idx] = reg[i];
      acc_logu[idx] = logu;
      acc_logr[idx] = ll[i] - mvnll[i];
      acc_ll[idx] = ll[i];
    }
  }
  ntot = i; /* total number examined */

  for (r = 0; r < nreg; r++) accpt[r] = 0;
  for (int j = 0; j < lst_size(retval); ++j) accpt[acc_region[j]]++;
  fprintf(stderr, "region-specific acceptance rates (overall %f): ",
          lst_size(retval)/(double)ntot);
  for (r = 0; r < nreg; r++)
    fprintf(stderr, "%d (%f) ", r, regnum[r] ? (double)accpt[r]/regnum[r] : 0.0);
  fprintf(stderr, "\n");
 
  /* check to see whether it is feasible to go forward */
  double init_acrt = lst_size(retval)/(double)ntot;
  if (init_acrt < 0.001)
    die("ERROR in nj_var_sample_rejection: acceptance rate %f too low.  Aborting.\n",
        init_acrt);

  /* if necessary, continue until target is met */
  while (lst_size(retval) < nsamples) {
    ntot++;
    do {
      nj_sample_points(mmvn, points_x, points_z);
      nj_apply_normalizing_flows(points_y, points_x, data, &logdet);
      nj_points_to_distances(points_y, data);
      mod->tree = nj_inf(data->dist, data->names, NULL, data);

      if (data->crispr_mod != NULL)
        lnl = cpr_compute_log_likelihood(data->crispr_mod, NULL);
      else
        lnl = nj_compute_log_likelihood(mod, data, NULL);

      if (!isfinite(lnl) || !isfinite(logdet)) tr_free(mod->tree);
    } while (!isfinite(lnl) || !isfinite(logdet)); 
    
    mvnl = mmvn_log_dens(mmvn, points_x) - logdet;
    z2 = vec_inner_prod(points_z, points_z);
    r = get_region(quants, z2);

    /* cooldown bookkeeping: count quiet proposals per region */
    for (int rr = 0; rr < nreg; ++rr) if (rr != r) since_viol[rr]++;
    since_viol[r] = 0;
    if (lnl - mvnl > logM[r]) { /* envelope violation: region-specific repair */
      double logr_new = lnl - mvnl;
      double gap = logr_new - logM[r];
      double base_bump = fmax(delta_min, fmax(2.0 * sigma_tail[r], gap_gain * gap));
      double bump = base_bump * pow(bump_gain, (double)viol_count[r]);
      viol_count[r]++;
      double new_logM = logr_new + bump;
      fprintf(stderr,
              "Region %d exceeded by %.6f (%.6f - %.6f): bump=%.3f (σ=%.3f, nviol=%d); revalidating region...\n",
              r, gap, logr_new, logM[r], bump, sigma_tail[r], viol_count[r]);
      logM[r] = new_logM;
      /* revalidate ONLY accepted samples from region r */
      List *new_ret = lst_new_ptr(nsamples);
      int new_n = 0;
      double new_avelnl = 0.0;
      for (int j = 0; j < lst_size(retval); ++j) {
        if (acc_region[j] != r) {
          /* keep sample from other regions */
          lst_push_ptr(new_ret, lst_get_ptr(retval, j));
          acc_region[new_n] = acc_region[j];
          acc_logu[new_n] = acc_logu[j];
          acc_logr[new_n] = acc_logr[j];
          acc_ll[new_n] = acc_ll[j];
          new_avelnl += acc_ll[j];
          new_n++;
          continue;
        }
        /* same region: keep only if still passing with updated logM[r] */
        if (acc_logu[j] <= acc_logr[j] - new_logM) {
          lst_push_ptr(new_ret, lst_get_ptr(retval, j));
          acc_region[new_n] = acc_region[j];
          acc_logu[new_n]   = acc_logu[j];
          acc_logr[new_n]   = acc_logr[j];
          acc_ll[new_n]     = acc_ll[j];
          new_avelnl       += acc_ll[j];
          new_n++;
        }
        else 
          /* drop invalid sample */
          tr_free(lst_get_ptr(retval, j));
      }
      /* swap in rebuilt accepted set */
      lst_free(retval);
      retval = new_ret;
      avelnl = new_avelnl;
      /* cooldown: let quiet regions relax their escalation */
      for (int rr = 0; rr < nreg; ++rr) {
        if (since_viol[rr] >= cooldown_trigger && viol_count[rr] > 0) {
          viol_count[rr] = (viol_count[rr] > cooldown_step) ? (viol_count[rr] - cooldown_step) : 0;
          since_viol[rr] = 0;
        }
      }
      /* discard the current (violating) proposal and continue */
      tr_free(mod->tree);
      continue;  /* do not restart; keep sampling */
    }

    logu = log(unif_rand());
    if (logu <= lnl - mvnl - logM[r]) {
      int idx = lst_size(retval);
      lst_push_ptr(retval, mod->tree);
      avelnl += lnl;
      
      /* record acceptance metadata */
      acc_region[idx] = r;
      acc_logu[idx] = logu;
      acc_logr[idx] = lnl - mvnl;
      acc_ll[idx] = lnl;
    }
    else
      tr_free(mod->tree);

    /* cooldown tick also on non-violating iterations */
    for (int rr = 0; rr < nreg; ++rr) {
      if (since_viol[rr] >= cooldown_trigger && viol_count[rr] > 0) {
        viol_count[rr] = (viol_count[rr] > cooldown_step) ? (viol_count[rr] - cooldown_step) : 0;
        since_viol[rr] = 0;
      }
    }
  }
  
  /* free any trees not used from initial set */
  for (i = 0; i < lst_size(init_samples); i++)
    if (retained[i] == FALSE)
      tr_free(lst_get_ptr(init_samples, i));

  if (logf != NULL)
    fprintf(logf, "# Rejection sampling from %d trees (acceptance rate %.3f); avelnl: %f\n",
            ntot, nsamples*1.0/ntot, avelnl/nsamples);
  
  lst_free(init_samples);
  vec_free(points_x);
  vec_free(points_y);
  vec_free(points_z);
  vec_free(quants);
  sfree(ll);
  sfree(mvnll);
  sfree(logM);
  sfree(sigma_tail);
  sfree(reg);
  sfree(retained);
  sfree(regnum);
  sfree(accpt);
  sfree(viol_count);
  sfree(since_viol);
  sfree(acc_region);
  sfree(acc_logu);
  sfree(acc_logr);
  sfree(acc_ll);
  return(retval);
}

/* Like nj_var_sample_rejection, but do shell-aware importance sampling
   with systematic resampling to return exactly nsamples trees. */
List *nj_var_sample_importance(int nsamples, multi_MVN *mmvn,
                               CovarData *data, TreeModel *mod,
                               FILE *logf) {
  int nprop = max(nsamples * 20, 20000);   
  int dim   = mmvn->d * mmvn->n;
  int nreg  = 12; 
  /* const double q_center = 0.990; /\* inner shells *\/ */
  /* const double q_tail   = 0.9990;/\* outer shells *\/ */

  /* outputs & workspaces */
  List *retval = lst_new_ptr(nsamples);
  List *props  = lst_new_ptr(nprop);

  Vector *points_x = vec_new(dim), *points_z = vec_new(dim),
    *points_y = vec_new(dim), *quants;

  /* per-proposal storage */
  double *logw = smalloc(nprop * sizeof(double));   /* log-weights = ll - mvnll */
  double *ll   = smalloc(nprop * sizeof(double));   /* (optional) diagnostics */
  double *mvnll = smalloc(nprop * sizeof(double));
  int *shell = smalloc(nprop * sizeof(int));

  /* shell diagnostics */
  int *regnum = smalloc(nreg * sizeof(int));
  for (int r = 0; r < nreg; ++r) regnum[r] = 0;

  /* build chi^2 shell boundaries */
  quants = vec_new(nreg + 1);
  vec_set(quants, 0, 0);
  for (int r = 1; r < nreg; r++)
    vec_set(quants, r, chisq_cdf_inv((double)r / nreg, dim));
  vec_set(quants, nreg, INFINITY);

  /* Proposal phase: draw nprop, compute log-weights */
  double logdet, z2, max_logw = -INFTY, lnl, mvnl;
  for (int i = 0; i < nprop; ++i) {
    /* draw from q(x) (MVN in whitened space), map through flow, infer tree, eval ll */
    do {
      nj_sample_points(mmvn, points_x, points_z);
      nj_apply_normalizing_flows(points_y, points_x, data, &logdet);
      nj_points_to_distances(points_y, data);
      mod->tree = nj_inf(data->dist, data->names, NULL, data);

      if (data->crispr_mod != NULL)
        lnl = cpr_compute_log_likelihood(data->crispr_mod, NULL);
      else
        lnl = nj_compute_log_likelihood(mod, data, NULL);

      if (!isfinite(lnl) || !isfinite(logdet)) tr_free(mod->tree);
    } while (!isfinite(lnl) || !isfinite(logdet));

    mvnl = mmvn_log_dens(mmvn, points_x) - logdet;  /* include flow Jacobian */
    ll[i] = lnl;
    mvnll[i] = mvnl;
    logw[i] = lnl - mvnl;

    /* record shell & keep the tree */
    z2 = vec_inner_prod(points_z, points_z);
    shell[i] = get_region(quants, z2);
    regnum[shell[i]]++;
    lst_push_ptr(props, mod->tree);

    if (logw[i] > max_logw) max_logw = logw[i];
  }

  /* Weight normalization & diagnostics */
  /* global numerically-stable normalization */
  double *w = smalloc(nprop * sizeof(double));
  double sumw = 0.0;
  for (int i = 0; i < nprop; ++i) {
    double wi = exp(logw[i] - max_logw);
    w[i] = wi;
    sumw += wi;
  }
  if (sumw == 0.0 || !isfinite(sumw)) {
    /* underflow case: fall back to selecting top nsamples by logw */
    int *idx = smalloc(nprop * sizeof(int));
    for (int i = 0; i < nprop; ++i) idx[i] = i;
    /* partial sort by descending logw; just use simple insertion sort */
    for (int i = 1; i < nprop; ++i) {
      int j = i, t = idx[i];
      while (j > 0 && logw[idx[j-1]] < logw[t]) { idx[j] = idx[j-1]; j--; }
      idx[j] = t;
    }
    for (int k = 0; k < nsamples; ++k)
      lst_push_ptr(retval, lst_get_ptr(props, idx[k]));
    /* free the rest */
    for (int k = nsamples; k < nprop; ++k)
      tr_free(lst_get_ptr(props, idx[k]));
    sfree(idx);
    goto IS_CLEANUP;
  }
  for (int i = 0; i < nprop; ++i) w[i] /= sumw;

  /* ESS diagnostic */
  double ess_denom = 0.0;
  for (int i = 0; i < nprop; ++i) ess_denom += w[i]*w[i];
  double ESS = (ess_denom > 0.0) ? (1.0/ess_denom) : 0.0;

  /* TEMPORARY: print mass per shell for tuning */
  double *mass = smalloc(nreg * sizeof(double));
  for (int r = 0; r < nreg; ++r) mass[r] = 0.0;
  for (int i = 0; i < nprop; ++i) mass[shell[i]] += w[i];
  fprintf(stderr, "IS: shell weight masses: ");
  for (int r = 0; r < nreg; ++r) fprintf(stderr, "%d(%.3f) ", r, mass[r]);
  fprintf(stderr, " | ESS=%.1f / %d\n", ESS, nsamples);
  sfree(mass);

  /* resampling */
  int *idx = smalloc(nsamples * sizeof(int));
  double u0 = unif_rand() / nsamples;
  double c  = w[0];
  int j = 0;
  for (int k = 0; k < nsamples; ++k) {
    double u = u0 + ((double)k)/nsamples;
    while (u > c && j < nprop-1) { j++; c += w[j]; }
    idx[k] = j;
  }

  /* build retval */
  for (int k = 0; k < nsamples; ++k)
    lst_push_ptr(retval, lst_get_ptr(props, idx[k]));

  /* free trees not selected */
  unsigned char *mark = (unsigned char*)smalloc(nprop * sizeof(unsigned char));
  memset(mark, 0, nprop * sizeof(unsigned char));
  for (int k = 0; k < nsamples; ++k) mark[idx[k]] = 1;
  for (int i = 0; i < nprop; ++i)
    if (!mark[i]) tr_free(lst_get_ptr(props, i));

  if (logf != NULL) {
    /* average log-likelihood of selected (for rough comparability to RS) */
    double avelnl = 0.0;
    for (int k = 0; k < nsamples; ++k) avelnl += ll[idx[k]];
    avelnl /= (double)nsamples;
    fprintf(logf, "# IS from %d trees; ESS≈%.1f; avelnl: %f\n",
            nprop, ESS, avelnl);
  }

  /* cleanup */
  sfree(mark);
  sfree(idx);

IS_CLEANUP:
  /* common cleanup */
  lst_free(props);
  vec_free(points_x);
  vec_free(points_y);
  vec_free(points_z);
  vec_free(quants);
  sfree(logw);
  sfree(ll);
  sfree(mvnll);
  sfree(w);
  sfree(shell);
  sfree(regnum);

  return retval;
}

/* ===================== PSIS-per-shell helpers ===================== */

/* Fit GPD to exceedances y[0..m-1] (ascending) using PWM L-moments.
   Returns (k_hat, sigma_hat). Clamp k for stability. */
static void gpd_fit_pwm(const double *y, int m, double *k_hat, double *sigma_hat) {
  if (m <= 1) { *k_hat = 0.0; *sigma_hat = (m==1? fmax(y[0],1e-12): 1.0); return; }
  const double a = 0.35; /* plotting-position offset */
  double b0 = 0.0, b1 = 0.0;
  for (int i = 0; i < m; ++i) {
    double Fi = ( (i+1) - a ) / (double)m;         /* approx CDF plotting position in (0,1] */
    if (Fi < 1e-12) Fi = 1e-12;
    if (Fi > 1.0) Fi = 1.0;
    b0 += y[i];
    b1 += y[i] * Fi;
  }
  b0 /= (double)m;
  b1 /= (double)m;

  /* L-moment relations for GPD:
     l1 = sigma/(1-k), l2 = sigma/((1-k)(2-k)), tau = l2/l1 = 1/(2-k).
     Estimate tau_hat = (2*b1 - b0)/b0, then k = 2 - 1/tau_hat, sigma = l1*(1-k) = b0*(1-k).
  */
  double tau = (2.0*b1 - b0) / fmax(b0, 1e-12);
  /* protect: if tau <= 0, fall back to k≈0 (exponential-like) */
  if (tau <= 1e-6) { *k_hat = 0.0; *sigma_hat = fmax(b0, 1e-12); return; }

  double k = 2.0 - 1.0 / tau;
  /* clamp k for stability; PSIS behaves well for k < ~0.7 */
  if (k < -0.5) k = -0.5;
  if (k > 0.9)  k = 0.9;

  double sigma = b0 * (1.0 - k);
  if (!(sigma > 0.0)) sigma = fmax(b0, 1e-12);

  *k_hat = k;
  *sigma_hat = sigma;
}

/* In-place PSIS smoothing for a single shell.
   Inputs:
     logw     : array of *global* log-weights (length n_all), mutated in-place for the shell indices
     idx      : indices (into logw) that belong to this shell (length m_all)
     m_all    : number of items in shell
     tail_frac, tail_nmin: define tail size m_tail
   Output:
     returns estimated Pareto k for the shell (via *k_out), and mutates the largest tail log-weights
     to smoothed values. Non-tail values unchanged. If m_tail <= 1, does nothing.
*/
static void psis_smooth_shell(double *logw, int *idx, int m_all,
                              double tail_frac, int tail_nmin,
                              double *k_out)
{
  *k_out = 0.0;
  if (m_all <= 2) return;

  /* sort shell indices by ascending logw */
  /* simple insertion sort for small m_all; replace with your sorter if preferred */
  for (int i = 1; i < m_all; ++i) {
    int t = idx[i], j = i;
    while (j > 0 && logw[idx[j-1]] > logw[t]) { idx[j] = idx[j-1]; j--; }
    idx[j] = t;
  }

  int m_tail = (int)ceil(tail_frac * m_all);
  if (m_tail < tail_nmin) m_tail = tail_nmin;
  if (m_tail > m_all)     m_tail = m_all;

  if (m_tail <= 1) return;

  /* threshold u is the smallest value in the tail block */
  int t0 = m_all - m_tail;                 /* first tail index in sorted order */
  double u = logw[idx[t0]];

  /* build exceedances y (ascending) */
  double *y = (double*)smalloc(m_tail * sizeof(double));
  for (int i = 0; i < m_tail; ++i) {
    double yi = logw[idx[t0 + i]] - u;
    y[i] = (yi > 0.0 ? yi : 0.0);
  }

  /* fit GPD by PWM */
  double k_hat, sigma_hat;
  gpd_fit_pwm(y, m_tail, &k_hat, &sigma_hat);
  *k_out = k_hat;

  /* replace tail with smoothed order stats:
     For i=1..m_tail (ascending), use p_i = (i - 0.5)/m_tail.
     GPD quantile for exceedance: Q(p) = sigma/k * ( (1-p)^(-k) - 1 )  (k != 0)
                                   Q(p) = sigma * log(1/(1-p))        (k == 0)
  */
  for (int i = 0; i < m_tail; ++i) {
    double p = ( (i + 1) - 0.5 ) / (double)m_tail; /* in (0,1) */
    if (p >= 1.0) p = 1.0 - 1e-12;
    if (p <= 0.0) p = 1e-12;

    double q; /* smoothed exceedance */
    if (fabs(k_hat) < 1e-8) {
      q = sigma_hat * log(1.0 / (1.0 - p));
    } else {
      q = (sigma_hat / k_hat) * ( pow(1.0 - p, -k_hat) - 1.0 );
    }
    logw[idx[t0 + i]] = u + q;
  }

  sfree(y);

  /* ensure monotonicity (ascending) after smoothing */
  for (int i = t0 + 1; i < m_all; ++i) {
    if (logw[idx[i]] < logw[idx[i-1]]) logw[idx[i]] = logw[idx[i-1]];
  }
}

/* helper: squared Euclidean distance between two rows of Z */
static inline double sqdist_Z(const double *Z, int dim, int ia, int ib) {
  const double *za = Z + (size_t)ia * (size_t)dim;
  const double *zb = Z + (size_t)ib * (size_t)dim;
  double s = 0.0, d;
  for (int k = 0; k < dim; ++k) { d = za[k] - zb[k]; s += d * d; }
  return s;
}

/* Importance sampling with PSIS-per-shell and Mixture-of-Centers (MoC)
   Two-level stratified resampling: centers -> shells -> proposals. */
List *nj_var_sample_importance_moc(int nsamples, multi_MVN *mmvn,
                                   CovarData *data, TreeModel *mod,
                                   FILE *logf)
{
  /* ---- knobs ---- */
  int nprop = max(nsamples * 30, 30000);
  int dim   = mmvn->d * mmvn->n;
  int nreg  = 8;
  const double tail_frac = 0.20;  /* PSIS tail fraction per shell */
  const int    tail_nmin = 20;
  const int    Kmax      = 8;     /* max centers */
  const int    seed_pool = 400;   /* candidates for farthest-point seeding */

  /* tempering + ridge */
  const double ess_target_frac = 0.12;  /* target ESS as frac of nprop */
  const int    beta_iters      = 30;    /* bisection iters for beta */
  const double beta_lo_floor   = 0.005; /* min beta */
  const double eps_max_center  = 0.80;  /* cap per-center ridge */
  const int    eps_it_center   = 25;    /* bisection iters for center ridge */
  const double ess_target_frac_shell = 0.08; /* per-shell ridge target */
  const double eps_max_shell   = 0.50;  /* cap per-shell ridge */
  const int    eps_it_shell    = 25;    /* bisection iters for shell ridge */
  /* ---------------- */

  List *retval = lst_new_ptr(nsamples);
  List *props  = lst_new_ptr(nprop);

  Vector *points_x = vec_new(dim), *points_z = vec_new(dim),
         *points_y = vec_new(dim), *quants;

  /* per-proposal storage */
  double *logw  = smalloc((size_t)nprop * sizeof(double));
  double *ll    = smalloc((size_t)nprop * sizeof(double));
  double *mvnll = smalloc((size_t)nprop * sizeof(double));
  int    *shell = smalloc((size_t)nprop * sizeof(int));
  double *Z     = smalloc((size_t)nprop * (size_t)dim * sizeof(double));

  /* build chi^2 shell boundaries */
  quants = vec_new(nreg + 1);
  vec_set(quants, 0, 0);
  for (int r = 1; r < nreg; r++)
    vec_set(quants, r, chisq_cdf_inv((double)r / nreg, dim));
  vec_set(quants, nreg, INFINITY);

  /* ---------- Propose & evaluate ---------- */
  double logdet, z2, lnl, mvnl;
  for (int i = 0; i < nprop; ++i) {
    do {
      nj_sample_points(mmvn, points_x, points_z);
      nj_apply_normalizing_flows(points_y, points_x, data, &logdet);
      nj_points_to_distances(points_y, data);
      mod->tree = nj_inf(data->dist, data->names, NULL, data);

      if (data->crispr_mod != NULL) lnl = cpr_compute_log_likelihood(data->crispr_mod, NULL);
      else                          lnl = nj_compute_log_likelihood(mod, data, NULL);

      if (!isfinite(lnl) || !isfinite(logdet)) tr_free(mod->tree);
    } while (!isfinite(lnl) || !isfinite(logdet));

    mvnl     = mmvn_log_dens(mmvn, points_x) - logdet; /* include flow Jacobian if any */
    ll[i]    = lnl;
    mvnll[i] = mvnl;
    logw[i]  = lnl - mvnl;

    /* stash z_i */
    for (int d = 0; d < dim; ++d) Z[(size_t)i*dim + d] = vec_get(points_z, d);

    z2 = vec_inner_prod(points_z, points_z);
    shell[i] = get_region(quants, z2);

    lst_push_ptr(props, mod->tree);
  }

  /* ---------- PSIS smoothing per shell (on logw) ---------- */
  int *counts = smalloc((size_t)nreg * sizeof(int));
  for (int r = 0; r < nreg; ++r) counts[r] = 0;
  for (int i = 0; i < nprop; ++i) counts[shell[i]]++;

  int **idxs = (int**)smalloc((size_t)nreg * sizeof(int*));
  for (int r = 0; r < nreg; ++r) {
    idxs[r] = (counts[r] > 0) ? (int*)smalloc((size_t)counts[r] * sizeof(int)) : NULL;
    counts[r] = 0; /* reuse as write ptr */
  }
  for (int i = 0; i < nprop; ++i) {
    int rr = shell[i];
    int pos = counts[rr]++;
    idxs[rr][pos] = i;
  }

  double *khat = smalloc((size_t)nreg * sizeof(double));
  for (int r = 0; r < nreg; ++r) {
    if (idxs[r] && counts[r] >= 2)
      psis_smooth_shell(logw, idxs[r], counts[r], tail_frac, tail_nmin, &khat[r]);
    else
      khat[r] = 0.0;
  }

  /* ---------- Normalize weights with tempering ---------- */
  double max_logw = -INFTY;
  for (int i = 0; i < nprop; ++i) if (logw[i] > max_logw) max_logw = logw[i];

  /* compute ESS at beta=1 */
  double s1 = 0.0, s2_all = 0.0;
  for (int i = 0; i < nprop; ++i) {
    double wi = exp(logw[i] - max_logw);
    s1 += wi; s2_all += wi * wi;
  }
  double ESS0 = (s2_all > 0.0) ? (s1*s1 / s2_all) : 0.0;
  double target_ess = ess_target_frac * (double)nprop;

  double beta = 1.0;
  if (ESS0 < target_ess) {
    double lo = beta_lo_floor, hi = 1.0;
    for (int it = 0; it < beta_iters; ++it) {
      double b = 0.5 * (lo + hi);
      double t1 = 0.0, t2 = 0.0;
      for (int i = 0; i < nprop; ++i) {
        double wi = exp(b * (logw[i] - max_logw));
        t1 += wi; t2 += wi * wi;
      }
      double ESSb = (t2 > 0.0) ? (t1*t1 / t2) : 0.0;
      if (ESSb >= target_ess) hi = b; else lo = b;
    }
    beta = 0.5 * (lo + hi);
  }

  /* apply tempering: logw <- beta * logw; recompute max */
  if (beta < 1.0) {
    for (int i = 0; i < nprop; ++i) logw[i] *= beta;
    max_logw = -INFTY;
    for (int i = 0; i < nprop; ++i) if (logw[i] > max_logw) max_logw = logw[i];
  }

  /* normalized weights */
  double *w  = smalloc((size_t)nprop * sizeof(double));
  double sumw = 0.0;
  for (int i = 0; i < nprop; ++i) { w[i] = exp(logw[i] - max_logw); sumw += w[i]; }

  if (!(sumw > 0.0) || !isfinite(sumw)) {
    /* fallback: take top-n by smoothed logw */
    fprintf(stderr, "# IS(MoC) numeric underflow; falling back to top-n by logw\n");
    int *order = smalloc((size_t)nprop * sizeof(int));
    for (int i = 0; i < nprop; ++i) order[i] = i;
    for (int i = 1; i < nprop; ++i) { int t = order[i], j = i;
      while (j > 0 && logw[order[j-1]] < logw[t]) { order[j] = order[j-1]; j--; }
      order[j] = t;
    }
    for (int k = 0; k < nsamples; ++k) lst_push_ptr(retval, lst_get_ptr(props, order[k]));
    for (int k = nsamples; k < nprop; ++k) tr_free(lst_get_ptr(props, order[k]));
    sfree(order);

    /* cleanup and return */
    for (int r = 0; r < nreg; ++r) if (idxs[r]) sfree(idxs[r]);
    sfree(idxs); sfree(khat); sfree(counts);
    lst_free(props);
    vec_free(points_x); vec_free(points_y); vec_free(points_z); vec_free(quants);
    sfree(logw); sfree(ll); sfree(mvnll); sfree(shell); sfree(Z); sfree(w);
    return retval;
  }
  for (int i = 0; i < nprop; ++i) w[i] /= sumw;

  /* ---- Optional global ridge if ESS still low ---- */
  double s2_now = 0.0; for (int i = 0; i < nprop; ++i) s2_now += w[i]*w[i];
  double ESS_real = (s2_now > 0.0) ? 1.0/s2_now : 0.0;
  if (ESS_real < target_ess) {
    const double eps_max = 0.50;
    const int    iters   = 25;
    double lo = 0.0, hi = eps_max, best_eps = 0.0;
    for (int it = 0; it < iters; ++it) {
      double eps = 0.5*(lo+hi);
      double s2b = 0.0, invN = 1.0/(double)nprop;
      for (int i = 0; i < nprop; ++i) {
        double wb = (1.0 - eps)*w[i] + eps*invN;
        s2b += wb*wb;
      }
      double ESSb = (s2b > 0.0) ? 1.0/s2b : 0.0;
      if (ESSb >= target_ess) { best_eps = eps; hi = eps; } else { lo = eps; }
    }
    if (best_eps > 0.0) {
      double invN = 1.0/(double)nprop, sw2 = 0.0;
      for (int i = 0; i < nprop; ++i) w[i] = (1.0 - best_eps)*w[i] + best_eps*invN;
      /* renorm (should be 1 already) */
      double swr = 0.0; for (int i = 0; i < nprop; ++i) swr += w[i];
      if (swr > 0.0) for (int i = 0; i < nprop; ++i) w[i] /= swr;
      for (int i = 0; i < nprop; ++i) sw2 += w[i]*w[i];
      ESS_real = (sw2 > 0.0) ? 1.0/sw2 : 0.0;
      fprintf(stderr, "#   ridge eps=%.3f -> ESS≈%.1f (target≈%.1f)\n",
              best_eps, ESS_real, target_ess);
    }
  }
  /* report chosen beta */
  {
    double s2b = 0.0;
    for (int i = 0; i < nprop; ++i) s2b += w[i]*w[i];
    double ESSb = (s2b > 0.0) ? 1.0/s2b : 0.0;
    fprintf(stderr, "#   tempering beta=%.3f -> ESS≈%.1f (target≈%.1f)\n",
            beta, ESSb, target_ess);
  }

  /* ---------- Discover K centers in z using weighted farthest-point ---------- */
  int  K = 0;
  int *centers = smalloc((size_t)Kmax * sizeof(int));
  int *ord     = smalloc((size_t)nprop * sizeof(int));
  for (int i = 0; i < nprop; ++i) ord[i] = i;
  /* sort by descending w */
  for (int i = 1; i < nprop; ++i) { int t = ord[i], j = i;
    while (j > 0 && w[ord[j-1]] < w[t]) { ord[j] = ord[j-1]; j--; }
    ord[j] = t;
  }
  {
    int poolN = (seed_pool < nprop ? seed_pool : nprop);
    if (poolN > 0) { centers[K++] = ord[0]; }
    for (int c = 1; c < Kmax && c < poolN; ++c) {
      int best_i = -1; double best_minD = -1.0;
      for (int p = 1; p < poolN; ++p) {
        int i = ord[p];
        double mind = INFTY;
        for (int kk = 0; kk < K; ++kk) {
          double d2 = sqdist_Z(Z, dim, i, centers[kk]);
          if (d2 < mind) mind = d2;
        }
        if (mind > best_minD) { best_minD = mind; best_i = i; }
      }
      if (best_i >= 0) centers[K++] = best_i; else break;
    }
  }

  /* ---------- Assign each proposal to nearest center ---------- */
  int *c_of = smalloc((size_t)nprop * sizeof(int));
  for (int i = 0; i < nprop; ++i) {
    int argmin = 0; double mind = INFTY;
    for (int kk = 0; kk < K; ++kk) {
      double d2 = sqdist_Z(Z, dim, i, centers[kk]);
      if (d2 < mind) { mind = d2; argmin = kk; }
    }
    c_of[i] = argmin;
  }

  /* masses */
  double *mass_c = smalloc((size_t)K * sizeof(double));
  for (int kk = 0; kk < K; ++kk) mass_c[kk] = 0.0;
  for (int i = 0; i < nprop; ++i) mass_c[c_of[i]] += w[i];

  double **mass_cs = (double**)smalloc((size_t)K * sizeof(double*));
  for (int kk = 0; kk < K; ++kk) {
    mass_cs[kk] = (double*)smalloc((size_t)nreg * sizeof(double));
    for (int r = 0; r < nreg; ++r) mass_cs[kk][r] = 0.0;
  }
  for (int i = 0; i < nprop; ++i) mass_cs[c_of[i]][ shell[i] ] += w[i];

  /* ---------- Per-center ridge blend ---------- */
  int *cnt_c = smalloc(K * sizeof(int));
  for (int kk = 0; kk < K; ++kk) cnt_c[kk] = 0;
  for (int i = 0; i < nprop; ++i) cnt_c[c_of[i]]++;

  for (int kk = 0; kk < K; ++kk) {
    int nk = cnt_c[kk];
    if (nk <= 1 || mass_c[kk] <= 0.0) continue;

    double s2c = 0.0;
    for (int i = 0; i < nprop; ++i) if (c_of[i] == kk) s2c += w[i]*w[i];
    double ESSc = (s2c > 0.0) ? (mass_c[kk]*mass_c[kk] / s2c) : 0.0;

    double target_c = ess_target_frac * (double)nprop * mass_c[kk];
    if (target_c < 1.0) target_c = 1.0;

    if (ESSc >= target_c) continue;

    double lo = 0.0, hi = eps_max_center, best = 0.0;
    for (int it = 0; it < eps_it_center; ++it) {
      double eps = 0.5*(lo+hi);
      double avg = mass_c[kk] / (double)nk;
      double s2b = 0.0;
      for (int i = 0; i < nprop; ++i) if (c_of[i] == kk) {
        double wb = (1.0 - eps)*w[i] + eps*avg;
        s2b += wb*wb;
      }
      double ESSb = (s2b > 0.0) ? (mass_c[kk]*mass_c[kk]/s2b) : 0.0;
      if (ESSb >= target_c) { best = eps; hi = eps; } else { lo = eps; }
    }
    if (best > 0.0) {
      double avg = mass_c[kk] / (double)nk;
      for (int i = 0; i < nprop; ++i) if (c_of[i] == kk)
        w[i] = (1.0 - best)*w[i] + best*avg;
    }
  }

  /* renormalize globally after per-center blends */
  {
    double sw = 0.0; for (int i = 0; i < nprop; ++i) sw += w[i];
    if (sw > 0.0) for (int i = 0; i < nprop; ++i) w[i] /= sw;
  }

  /* ---------- Per-shell ridge blend ---------- */
  {
    int    *cnt_s      = smalloc(nreg * sizeof(int));
    double *mass_shell1 = smalloc(nreg * sizeof(double));
    for (int r = 0; r < nreg; ++r) { cnt_s[r] = 0; mass_shell1[r] = 0.0; }
    for (int i = 0; i < nprop; ++i) { cnt_s[shell[i]]++; mass_shell1[shell[i]] += w[i]; }

    for (int r = 0; r < nreg; ++r) {
      int nr = cnt_s[r];
      double mr = mass_shell1[r];
      if (nr <= 1 || mr <= 0.0) continue;

      double s2r = 0.0;
      for (int i = 0; i < nprop; ++i) if (shell[i] == r) s2r += w[i]*w[i];
      double ESSr = (s2r > 0.0) ? (mr*mr / s2r) : 0.0;

      double target_r = ess_target_frac_shell * (double)nprop * mr;
      if (target_r < 1.0) target_r = 1.0;
      if (ESSr >= target_r) continue;

      double lo = 0.0, hi = eps_max_shell, best = 0.0;
      for (int it = 0; it < eps_it_shell; ++it) {
        double eps = 0.5*(lo+hi);
        double avg = mr / (double)nr;
        double s2b = 0.0;
        for (int i = 0; i < nprop; ++i) if (shell[i] == r) {
          double wb = (1.0 - eps)*w[i] + eps*avg;
          s2b += wb*wb;
        }
        double ESSb = (s2b > 0.0) ? (mr*mr / s2b) : 0.0;
        if (ESSb >= target_r) { best = eps; hi = eps; } else { lo = eps; }
      }
      if (best > 0.0) {
        double avg = mr / (double)nr;
        for (int i = 0; i < nprop; ++i) if (shell[i] == r)
          w[i] = (1.0 - best)*w[i] + best*avg;
      }
    }
    /* renormalize globally after per-shell blends */
    double sw = 0.0; for (int i = 0; i < nprop; ++i) sw += w[i];
    if (sw > 0.0) for (int i = 0; i < nprop; ++i) w[i] /= sw;

    sfree(cnt_s);
    sfree(mass_shell1);
  }

  /* ---------- Diagnostics ---------- */
  {
    int topN = (seed_pool < 10 ? seed_pool : 10);
    if (topN > nprop) topN = nprop;
    int *ord2 = smalloc((size_t)nprop * sizeof(int));
    for (int i = 0; i < nprop; ++i) ord2[i] = i;
    for (int i = 1; i < nprop; ++i) { int t = ord2[i], j = i;
      while (j > 0 && w[ord2[j-1]] < w[t]) { ord2[j] = ord2[j-1]; j--; }
      ord2[j] = t;
    }
    double top10 = 0.0, wmax = 0.0;
    for (int k = 0; k < topN; ++k) top10 += w[ord2[k]];
    if (nprop > 0) wmax = w[ord2[0]];
    sfree(ord2);

    double ess_denom = 0.0; for (int i = 0; i < nprop; ++i) ess_denom += w[i]*w[i];
    double ESS = (ess_denom > 0.0) ? (1.0/ess_denom) : 0.0;

    double *mass_shell2 = smalloc((size_t)nreg * sizeof(double));
    double *den_shell2  = smalloc((size_t)nreg * sizeof(double));
    for (int r = 0; r < nreg; ++r) { mass_shell2[r]=0.0; den_shell2[r]=0.0; }
    for (int i = 0; i < nprop; ++i) {
      mass_shell2[shell[i]] += w[i];
      den_shell2[shell[i]]  += w[i]*w[i];
    }

    fprintf(stderr,"# IS(MoC) diag: K=%d centers, top1=%.3f, top10=%.3f, ESS=%.1f/%d\n",
            K, wmax, top10, ESS, nprop);
    fprintf(stderr,"#   shell mass & ESS_r:");
    for (int r = 0; r < nreg; ++r) {
      double ESSr = (den_shell2[r] > 0.0) ? (mass_shell2[r]*mass_shell2[r]/den_shell2[r]) : 0.0;
      fprintf(stderr," %d:(m=%.3f, ESS=%.1f)", r, mass_shell2[r], ESSr);
    }
    fprintf(stderr,"\n#   center masses:");
    for (int kk = 0; kk < K; ++kk) fprintf(stderr," %d:%.3f", kk, mass_c[kk]);
    fprintf(stderr,"\n#   k-hat per shell:");
    for (int r = 0; r < nreg; ++r) fprintf(stderr," %d:%.2f", r, khat[r]);
    fprintf(stderr,"\n");

    sfree(mass_shell2);
    sfree(den_shell2);
  }

  /* ---------- Two-level stratified resampling (center -> shell -> proposals) ---------- */
  int *q_c = smalloc((size_t)K * sizeof(int));
  int taken = 0;
  for (int kk = 0; kk < K; ++kk) {
    double want = mass_c[kk] * nsamples;
    int qc = (int)floor(want); if (qc < 0) qc = 0;
    q_c[kk] = qc; taken += qc;
  }
  {
    int rem = nsamples - taken;
    if (rem > 0) {
      double *res = smalloc((size_t)K * sizeof(double));
      int *ordc   = smalloc((size_t)K * sizeof(int));
      for (int kk = 0; kk < K; ++kk) { res[kk] = mass_c[kk]*nsamples - q_c[kk]; if (res[kk] < 0.0) res[kk]=0.0; ordc[kk]=kk; }
      for (int i = 1; i < K; ++i) { int t = ordc[i], j = i;
        while (j > 0 && res[ordc[j-1]] < res[t]) { ordc[j] = ordc[j-1]; j--; }
        ordc[j] = t;
      }
      for (int k = 0; k < rem; ++k) q_c[ordc[k]]++;
      sfree(res); sfree(ordc);
    }
  }

  int **q_cs = (int**)smalloc((size_t)K * sizeof(int*));
  for (int kk = 0; kk < K; ++kk) {
    q_cs[kk] = (int*)smalloc((size_t)nreg * sizeof(int));
    int want = q_c[kk], got = 0;
    for (int r = 0; r < nreg; ++r) {
      double p = (mass_c[kk] > 0.0) ? (mass_cs[kk][r] / mass_c[kk]) : 0.0;
      int qc = (int)floor(p * want); if (qc < 0) qc = 0;
      q_cs[kk][r] = qc; got += qc;
    }
    int need = want - got;
    if (need > 0) {
      double *resr = smalloc((size_t)nreg * sizeof(double));
      int *ordr    = smalloc((size_t)nreg * sizeof(int));
      for (int r = 0; r < nreg; ++r) {
        double p = (mass_c[kk] > 0.0) ? (mass_cs[kk][r] / mass_c[kk]) : 0.0;
        resr[r] = p * want - q_cs[kk][r]; if (resr[r] < 0.0) resr[r] = 0.0; ordr[r] = r;
      }
      for (int i = 1; i < nreg; ++i) { int t = ordr[i], j = i;
        while (j > 0 && resr[ordr[j-1]] < resr[t]) { ordr[j] = ordr[j-1]; j--; }
        ordr[j] = t;
      }
      for (int k = 0; k < need; ++k) q_cs[kk][ ordr[k] ]++;
      sfree(resr); sfree(ordr);
    }
  }

  /* prepare (center,shell) index lists */
  int **idx_cs_count = (int**)smalloc((size_t)K * sizeof(int*));
  int **idx_cs_start = (int**)smalloc((size_t)K * sizeof(int*));
  for (int kk = 0; kk < K; ++kk) {
    idx_cs_count[kk] = (int*)smalloc((size_t)nreg * sizeof(int));
    idx_cs_start[kk] = (int*)smalloc((size_t)nreg * sizeof(int));
    for (int r = 0; r < nreg; ++r) idx_cs_count[kk][r] = 0;
  }

  int *cell_sizes = smalloc((size_t)K * (size_t)nreg * sizeof(int));
  for (int kk = 0; kk < K; ++kk) for (int r = 0; r < nreg; ++r) cell_sizes[kk*nreg + r] = 0;
  for (int i = 0; i < nprop; ++i) cell_sizes[c_of[i]*nreg + shell[i]]++;

  int **idx_cs = (int**)smalloc((size_t)K * sizeof(int*));
  for (int kk = 0; kk < K; ++kk) {
    idx_cs[kk] = (int*)smalloc((size_t)nprop * sizeof(int)); /* upper bound; use prefix */
    int off = 0;
    for (int r = 0; r < nreg; ++r) { idx_cs_start[kk][r] = off; off += cell_sizes[kk*nreg + r]; }
  }

  int *cursor = smalloc((size_t)K * (size_t)nreg * sizeof(int));
  for (int kk = 0; kk < K; ++kk) for (int r = 0; r < nreg; ++r) cursor[kk*nreg + r] = 0;
  for (int i = 0; i < nprop; ++i) {
    int kk = c_of[i], rr = shell[i];
    int pos = idx_cs_start[kk][rr] + cursor[kk*nreg + rr];
    idx_cs[kk][pos] = i;
    cursor[kk*nreg + rr]++;
  }
  for (int kk = 0; kk < K; ++kk)
    for (int r = 0; r < nreg; ++r)
      idx_cs_count[kk][r] = cursor[kk*nreg + r];

  /* pick samples */
  int picked = 0;
  unsigned char *mark = (unsigned char*)smalloc((size_t)nprop);
  memset(mark, 0, (size_t)nprop);

  for (int kk = 0; kk < K; ++kk) {
    for (int r = 0; r < nreg; ++r) {
      int need = q_cs[kk][r];
      int m = idx_cs_count[kk][r];
      if (need <= 0 || m <= 0) continue;

      double s = 0.0;
      for (int j = 0; j < m; ++j)
        s += w[idx_cs[kk][ idx_cs_start[kk][r] + j ]];
      if (s <= 0.0) continue;

      double *win = smalloc((size_t)m * sizeof(double));
      for (int j = 0; j < m; ++j)
        win[j] = w[idx_cs[kk][ idx_cs_start[kk][r] + j ]] / s;

      int *copies = smalloc((size_t)m * sizeof(int));
      int n_det = 0;
      for (int j = 0; j < m; ++j) {
        double want = need * win[j];
        int c = (int)floor(want);
        if (c < 0) c = 0;
        copies[j] = c;
        n_det += c;
      }
      int remr = need - n_det;

      for (int j = 0; j < m && picked < nsamples; ++j) {
        for (int t = 0; t < copies[j] && picked < nsamples; ++t) {
          int ii = idx_cs[kk][ idx_cs_start[kk][r] + j ];
          lst_push_ptr(retval, lst_get_ptr(props, ii));
          mark[ii] = 1; picked++;
        }
      }
      if (picked == nsamples) { sfree(copies); sfree(win); break; }

      if (remr > 0) {
        double *vres = smalloc((size_t)m * sizeof(double));
        double sres = 0.0;
        for (int j = 0; j < m; ++j) {
          double want = need * win[j];
          double frac = want - floor(want);
          if (frac < 0.0) frac = 0.0;
          vres[j] = frac; sres += frac;
        }
        if (sres > 0.0) {
          for (int j = 0; j < m; ++j) vres[j] /= sres;
          double u0 = unif_rand() / remr, c = vres[0];
          int jj = 0;
          for (int k = 0; k < remr && picked < nsamples; ++k) {
            double u = u0 + ((double)k)/remr;
            while (u > c && jj < m - 1) { jj++; c += vres[jj]; }
            int ii = idx_cs[kk][ idx_cs_start[kk][r] + jj ];
            lst_push_ptr(retval, lst_get_ptr(props, ii));
            mark[ii] = 1; picked++;
          }
        }
        sfree(vres);
      }
      sfree(copies);
      sfree(win);
      if (picked == nsamples) break;
    }
    if (picked == nsamples) break;
  }

  /* global top-up if rounding left us short */
  while (picked < nsamples) {
    double u0 = unif_rand() / (nsamples - picked);
    double c = w[0]; int j = 0;
    for (int k = 0; k < nsamples - picked; ++k) {
      double u = u0 + ((double)k)/(nsamples - picked);
      while (u > c && j < nprop-1) { j++; c += w[j]; }
      lst_push_ptr(retval, lst_get_ptr(props, j));
      mark[j] = 1;
    }
    picked = nsamples;
  }

  /* free unselected trees */
  for (int i = 0; i < nprop; ++i)
    if (!mark[i]) tr_free(lst_get_ptr(props, i));

  /* light footprint diagnostics: kept per center */
  {
    int *center_ret = smalloc((size_t)K * sizeof(int));
    for (int kk = 0; kk < K; ++kk) center_ret[kk] = 0;
    for (int i = 0, kept = 0; i < nprop && kept < nsamples; ++i) {
      if (mark[i]) { center_ret[ c_of[i] ]++; kept++; }
    }
    fprintf(stderr, "#   kept per center:"); for (int kk = 0; kk < K; ++kk) fprintf(stderr," %d:%d", kk, center_ret[kk]);
    fprintf(stderr,"\n# IS(MoC) from %d props; final nsamples=%d\n", nprop, nsamples);
    sfree(center_ret);
  }

  /* -------- cleanup -------- */
  for (int r = 0; r < nreg; ++r) if (idxs[r]) sfree(idxs[r]);
  sfree(idxs);
  sfree(khat);
  sfree(counts);
  lst_free(props);
  vec_free(points_x);
  vec_free(points_y);
  vec_free(points_z);
  vec_free(quants);
  sfree(logw);
  sfree(ll);
  sfree(mvnll);
  sfree(shell);
  sfree(Z);
  sfree(w);
  sfree(ord);
  sfree(centers);
  sfree(c_of);
  if (mass_cs) { for (int kk = 0; kk < K; ++kk) sfree(mass_cs[kk]); sfree(mass_cs); }
  sfree(mass_c);
  if (q_cs) { for (int kk = 0; kk < K; ++kk) sfree(q_cs[kk]); sfree(q_cs); }
  if (idx_cs) { for (int kk = 0; kk < K; ++kk) sfree(idx_cs[kk]); sfree(idx_cs); }
  if (idx_cs_count){ for (int kk=0; kk<K; ++kk) sfree(idx_cs_count[kk]); sfree(idx_cs_count); }
  if (idx_cs_start){ for (int kk=0; kk<K; ++kk) sfree(idx_cs_start[kk]); sfree(idx_cs_start); }
  sfree(cell_sizes);
  sfree(cursor);
  sfree(cnt_c);
  sfree(mark);

  return retval;
}

/* ===== Adaptive Tempered SMC with MH rejuvenation (pure C, TreeNode*) =====
   - Bridges q(x) -> posterior with beta in [0,1]
   - Chooses beta steps by ESS target
   - Systematic resampling when ESS drops
   - Independence-MH rejuvenation using mmvn at current beta
   Returns nsamples TreeNode* (duplicates possible).
*/

static inline double smc_normalize_and_ess(const double *logw_in, double *w_out, int M) {
  int j;
  double maxlw = -INFTY;
  for (j = 0; j < M; ++j) if (logw_in[j] > maxlw) maxlw = logw_in[j];
  double sw = 0.0;
  for (j = 0; j < M; ++j) { w_out[j] = exp(logw_in[j] - maxlw); sw += w_out[j]; }
  if (!(sw > 0.0) || !isfinite(sw)) {
    for (j = 0; j < M; ++j) w_out[j] = 1.0 / (double)M;
    return (double)M;
  }
  for (j = 0; j < M; ++j) w_out[j] /= sw;
  double s2 = 0.0;
  for (j = 0; j < M; ++j) s2 += w_out[j]*w_out[j];
  return (s2 > 0.0) ? 1.0/s2 : 0.0;
}

static inline void smc_systematic_resample(const double *w_in, int M, int *idx_out) {
  int j = 0;
  double u0 = unif_rand() / (double)M;
  double c = w_in[0];
  for (int i = 0; i < M; ++i) {
    double u = u0 + ((double)i)/ (double)M;
    while (u > c && j < M-1) { j++; c += w_in[j]; }
    idx_out[i] = j;
  }
}

/* Pick next beta via bisection to reach ESS target.
   Uses w_work as scratch (length M). */
static inline double smc_choose_next_beta(double beta_curr,
                                          const double *logw_curr,
                                          const double *logr,
                                          int M, double ess_target,
                                          double *w_work) {
  if (beta_curr >= 1.0) return 1.0;

  /* If beta=1 already meets target, jump to 1 */
  double *tmp = (double*)smalloc((size_t)M * sizeof(double));
  for (int j = 0; j < M; ++j) tmp[j] = logw_curr[j] + (1.0 - beta_curr) * logr[j];
  double ESS1 = smc_normalize_and_ess(tmp, w_work, M);
  sfree(tmp);
  if (ESS1 >= ess_target) return 1.0;

  double blo = beta_curr, bhi = 1.0, bmid;
  int it, maxit = 30;
  for (it = 0; it < maxit; ++it) {
    bmid = 0.5*(blo + bhi);
    double *t = (double*)smalloc((size_t)M * sizeof(double));
    for (int j = 0; j < M; ++j) t[j] = logw_curr[j] + (bmid - beta_curr) * logr[j];
    double ESS = smc_normalize_and_ess(t, w_work, M);
    sfree(t);
    if (ESS >= ess_target) blo = bmid; else bhi = bmid;
    if (bhi - blo < 1e-4) break;
  }
  bmid = 0.5*(blo + bhi);
  if (bmid - beta_curr < 1e-3) bmid = beta_curr + 1e-3; /* min step */
  if (bmid > 1.0) bmid = 1.0;
  return bmid;
}

/* One independence-MH rejuvenation step at beta for particle k.
   Proposes from mmvn; accepts w.p. min(1, exp(beta*(logr_prop - logr_curr))).
   Keeps mod->tree consistent (restores on rejection). */
static inline int smc_mh_rejuvenate_one(int k, double beta_t,
                                        multi_MVN *mmvn,
                                        CovarData *data, TreeModel *mod,
                                        Vector *points_x, Vector *points_z, Vector *points_y,
                                        int dim, double *X, double *ll, double *mvnll,
                                        TreeNode **trees) {
  double logdet, lnlp, mvnlp, logr_curr, logr_prop, log_alpha, u;

  /* Propose x' ~ q */
  nj_sample_points(mmvn, points_x, points_z);
  nj_apply_normalizing_flows(points_y, points_x, data, &logdet);
  nj_points_to_distances(points_y, data);
  TreeNode *tprop = nj_inf(data->dist, data->names, NULL, data);

  if (data->crispr_mod != NULL) lnlp = cpr_compute_log_likelihood(data->crispr_mod, NULL);
  else                          lnlp = nj_compute_log_likelihood(mod, data, NULL);
  if (!isfinite(lnlp) || !isfinite(logdet)) { tr_free(tprop); return 0; }
  mvnlp = mmvn_log_dens(mmvn, points_x) - logdet;

  logr_curr = ll[k] - mvnll[k];
  logr_prop = lnlp  - mvnlp;

  log_alpha = beta_t * (logr_prop - logr_curr);
  u = log(unif_rand());
  if (u < log_alpha) {
    /* accept */
    for (int d = 0; d < dim; ++d) X[(size_t)k*dim + d] = vec_get(points_x, d);
    tr_free(trees[k]);
    trees[k] = tprop;
    ll[k]    = lnlp;
    mvnll[k] = mvnlp;
    mod->tree = trees[k];
    return 1;
  } else {
    /* reject */
    tr_free(tprop);
    mod->tree = trees[k];
    return 0;
  }
}

List *nj_var_sample_smc(int nsamples, multi_MVN *mmvn,
                        CovarData *data, TreeModel *mod,
                        FILE *logf)
{
  /* ---- knobs ---- */
  int    N                = nsamples;  /* particle count */
  int    dim              = mmvn->d * mmvn->n;
  int    max_stages       = 200;
  double ess_target_frac  = 0.60;      /* target ESS fraction per stage */
  double resamp_thresh    = 0.50;      /* resample if ESS/N below this */
  int    rejuvenation_MH  = 2;         /* MH steps after each resample */
  /* --------------- */

  List *retval = lst_new_ptr(nsamples);

  /* particle state */
  double   *X     = (double*)smalloc((size_t)N * (size_t)dim * sizeof(double));
  double   *ll    = (double*)smalloc((size_t)N * sizeof(double));
  double   *mvnll = (double*)smalloc((size_t)N * sizeof(double));
  double   *logw  = (double*)smalloc((size_t)N * sizeof(double));
  double   *w     = (double*)smalloc((size_t)N * sizeof(double));
  TreeNode **trees= (TreeNode**)smalloc((size_t)N * sizeof(TreeNode*));

  Vector *points_x = vec_new(dim);
  Vector *points_z = vec_new(dim);
  Vector *points_y = vec_new(dim);

  /* -------- initialization: beta=0 (from proposal) -------- */
  {
    double logdet, lnl, mvnl;
    for (int i = 0; i < N; ++i) {
      do {
        nj_sample_points(mmvn, points_x, points_z);
        nj_apply_normalizing_flows(points_y, points_x, data, &logdet);
        nj_points_to_distances(points_y, data);
        trees[i] = nj_inf(data->dist, data->names, NULL, data);

        if (data->crispr_mod != NULL) lnl = cpr_compute_log_likelihood(data->crispr_mod, NULL);
        else                          lnl = nj_compute_log_likelihood(mod, data, NULL);

        if (!isfinite(lnl) || !isfinite(logdet)) tr_free(trees[i]);
      } while (!isfinite(lnl) || !isfinite(logdet));

      for (int d = 0; d < dim; ++d) X[(size_t)i*dim + d] = vec_get(points_x, d);
      mvnl     = mmvn_log_dens(mmvn, points_x) - logdet;
      ll[i]    = lnl;
      mvnll[i] = mvnl;
      logw[i]  = 0.0;  /* uniform at beta=0 */
      mod->tree = trees[i]; /* keep model consistent */
    }
  }

  /* precompute logr = ll - mvnll (used repeatedly) */
  double *logr = (double*)smalloc((size_t)N * sizeof(double));
  for (int i = 0; i < N; ++i) logr[i] = ll[i] - mvnll[i];

  /* scratch for choose_next_beta */
  double *w_work = (double*)smalloc((size_t)N * sizeof(double));

  /* -------- tempering loop -------- */
  double beta = 0.0;
  int stage = 0;
  for (; stage < max_stages && beta < 1.0; ++stage) {
    double ess_target = ess_target_frac * (double)N;

    /* pick beta_{t+1} */
    double beta_next = smc_choose_next_beta(beta, logw, logr, N, ess_target, w_work);
    double delta = beta_next - beta;

    /* update log-weights */
    for (int i = 0; i < N; ++i) logw[i] += delta * logr[i];

    /* normalize and report ESS */
    double ESS = smc_normalize_and_ess(logw, w, N);
    fprintf(stderr, "# SMC: stage=%d beta=%.3f->%.3f (Δ=%.3f) ESS=%.1f/%d\n",
            stage, beta, beta_next, delta, ESS, N);

    beta = beta_next;

    /* resample if needed (or at final beta to equalize weights) */
    if (ESS < resamp_thresh * (double)N || beta >= 1.0) {
      int *anc = (int*)smalloc((size_t)N * sizeof(int));
      smc_systematic_resample(w, N, anc);

      /* count how many times each ancestor is used */
      int *counts = (int*)smalloc((size_t)N * sizeof(int));
      for (int i = 0; i < N; ++i) counts[i] = 0;
      for (int i = 0; i < N; ++i) counts[anc[i]]++;

      /* allocate new arrays */
      double   *Xnew = (double*)smalloc((size_t)N * (size_t)dim * sizeof(double));
      double   *lln  = (double*)smalloc((size_t)N * sizeof(double));
      double   *mvn  = (double*)smalloc((size_t)N * sizeof(double));
      TreeNode **tn  = (TreeNode**)smalloc((size_t)N * sizeof(TreeNode*));

      for (int i = 0; i < N; ++i) {
        int a = anc[i];
        /* copy state */
        for (int d = 0; d < dim; ++d) Xnew[(size_t)i*dim + d] = X[(size_t)a*dim + d];
        lln[i]  = ll[a];
        mvn[i]  = mvnll[a];
        tn[i]   = trees[a];
      }

      /* free trees that were not selected */
      for (int i = 0; i < N; ++i) if (counts[i] == 0) tr_free(trees[i]);

      /* swap in */
      sfree(X);     X     = Xnew;
      sfree(ll);    ll    = lln;
      sfree(mvnll); mvnll = mvn;
      sfree(trees); trees = tn;

      /* reset weights after resampling */
      for (int i = 0; i < N; ++i) { w[i] = 1.0/(double)N; logw[i] = 0.0; }

      sfree(anc);
      sfree(counts);

      /* rejuvenation at current beta */
      if (rejuvenation_MH > 0 && beta < 1.0000001) {
        int acc_total = 0;
        for (int step = 0; step < rejuvenation_MH; ++step)
          for (int k = 0; k < N; ++k)
            acc_total += smc_mh_rejuvenate_one(k, beta, mmvn, data, mod,
                                               points_x, points_z, points_y,
                                               dim, X, ll, mvnll, trees);
        for (int i = 0; i < N; ++i) logr[i] = ll[i] - mvnll[i];
        fprintf(stderr, "#   rejuvenation@beta=%.3f: MH accepts %d / %d\n",
                beta, acc_total, N * rejuvenation_MH);
      }
    }
  }

  /* -------- output -------- */
  for (int i = 0; i < N; ++i) lst_push_ptr(retval, trees[i]);

  fprintf(stderr, "# SMC finished: stages=%d, final beta=%.3f, returned %d samples\n",
          stage, beta, nsamples);

  /* -------- cleanup (not freeing returned TreeNode* in retval) -------- */
  sfree(X);
  sfree(ll);
  sfree(mvnll);
  sfree(logw);
  sfree(w);
  sfree(logr);
  sfree(w_work);
  sfree(trees);
  vec_free(points_x);
  vec_free(points_y);
  vec_free(points_z);

  return retval;
}

/* ===== pCN MCMC in MVN parameter space (pure C, TreeNode*) ==================
   - Prior: x ~ mmvn  (proposal preserves this prior exactly)
   - Proposal: x' = sqrt(1-rho^2) * x + rho * nu,  nu ~ mmvn
   - Accept w.p. min(1, exp(lnL(x') - lnL(x)))      (prior cancels)
   - Optional normalizing flows are used only to build the tree (likelihood).
   - Simple Robbins–Monro adaptation of rho during burn-in to ~0.30 acc rate.

   Returns nsamples trees; duplicates possible (typical for MCMC).
   Diagnostics printed to stderr.
============================================================================= */

List *nj_var_sample_pcn(int nsamples, multi_MVN *mmvn,
                        CovarData *data, TreeModel *mod,
                        FILE *logf /* unused; we print to stderr */)
{
  /* ---- knobs (tune if needed) ------------------------------------------ */
  const int    thin         = 10;          /* keep 1 every 'thin' iters           */
  const int    burn_keep    = 1000;        /* burn-in iterations (not kept)       */
  const double rho_init     = 0.20;        /* initial step size (0<rho<1)         */
  const double acc_target   = 0.30;        /* target MH acceptance during burn-in */
  const double adapt_gamma0 = 10.0;        /* adaptation strength constant        */
  const int    adapt_stop   = 8000;        /* stop adapting after this many iters */
  /* ---------------------------------------------------------------------- */

  int dim = mmvn->d * mmvn->n;

  /* total iterations = burn + kept*thin */
  int kept_needed = nsamples;
  int iters_needed = burn_keep + kept_needed * thin;

  /* output container */
  List *retval = lst_new_ptr(nsamples);

  /* vectors reused */
  Vector *points_x = vec_new(dim);   /* workspace to evaluate a given x */
  Vector *points_z = vec_new(dim);   /* unused except when sampling nu  */
  Vector *points_y = vec_new(dim);

  /* state for current position x */
  double *x_cur = (double*)smalloc((size_t)dim * sizeof(double));
  double *x_prop = (double*)smalloc((size_t)dim * sizeof(double));
  double logdet, lnl_cur, lnl_prop;

  /* --- initialize from prior (mmvn) --- */
  {
    do {
      nj_sample_points(mmvn, points_x, points_z);                /* draws x ~ mmvn */
      nj_apply_normalizing_flows(points_y, points_x, data, &logdet);
      nj_points_to_distances(points_y, data);
      mod->tree = nj_inf(data->dist, data->names, NULL, data);

      if (data->crispr_mod != NULL) lnl_cur = cpr_compute_log_likelihood(data->crispr_mod, NULL);
      else                          lnl_cur = nj_compute_log_likelihood(mod, data, NULL);

      if (!isfinite(lnl_cur) || !isfinite(logdet)) tr_free(mod->tree);
    } while (!isfinite(lnl_cur) || !isfinite(logdet));

    for (int d = 0; d < dim; ++d) x_cur[d] = vec_get(points_x, d);
  }
  TreeNode *t_cur = mod->tree;  /* current tree */

  /* proposal scratch: we only need nu ~ mmvn each iteration */
  Vector *nu_x = vec_new(dim), *nu_z = vec_new(dim);

  /* pCN step size (adapted during burn-in) */
  double rho = rho_init;
  int    acc_burn = 0, try_burn = 0;

  int kept = 0;
  for (int it = 1; it <= iters_needed; ++it) {
    /* draw nu ~ mmvn */
    nj_sample_points(mmvn, nu_x, nu_z);

    /* x_prop = sqrt(1-rho^2)*x_cur + rho*nu */
    double a = sqrt(fmax(0.0, 1.0 - rho*rho));
    for (int d = 0; d < dim; ++d) {
      x_prop[d] = a * x_cur[d] + rho * vec_get(nu_x, d);
      vec_set(points_x, d, x_prop[d]);
    }

    /* evaluate likelihood at x_prop (flows OK; prior cancels in MH) */
    nj_apply_normalizing_flows(points_y, points_x, data, &logdet);
    nj_points_to_distances(points_y, data);
    TreeNode *t_prop = nj_inf(data->dist, data->names, NULL, data);

    if (data->crispr_mod != NULL) lnl_prop = cpr_compute_log_likelihood(data->crispr_mod, NULL);
    else                          lnl_prop = nj_compute_log_likelihood(mod, data, NULL);

    int accept = 0;
    if (isfinite(lnl_prop) && isfinite(logdet)) {
      double log_alpha = lnl_prop - lnl_cur;           /* prior cancels under pCN */
      double u = log(unif_rand());
      if (u < log_alpha) accept = 1;
    }

    if (it <= burn_keep) { try_burn++; if (accept) acc_burn++; }

    if (accept) {
      /* move: replace current state */
      for (int d = 0; d < dim; ++d) x_cur[d] = x_prop[d];
      tr_free(t_cur);
      t_cur = t_prop;
      lnl_cur = lnl_prop;
      mod->tree = t_cur;
    } else {
      /* reject */
      tr_free(t_prop);
      mod->tree = t_cur;
    }

    /* --- adapt rho during burn-in toward acc_target --- */
    if (it <= adapt_stop && it <= burn_keep) {
      /* Robbins–Monro on logit(rho); simple stable rule */
      double step = adapt_gamma0 / (adapt_gamma0 + (double)it);
      double adj  = (accept ? 1.0 : 0.0) - acc_target;
      /* update on unconstrained scale; keep rho in (1e-4, 0.999) */
      double r2 = rho*rho;
      /* small-gradient update on rho directly (safe for modest step sizes) */
      rho += step * adj * 0.05;             /* 0.05 is a mild gain */
      if (rho < 1e-4) rho = 1e-4;
      if (rho > 0.999) rho = 0.999;
    }

    /* keep (thin) samples after burn-in */
    if (it > burn_keep && ((it - burn_keep) % thin == 0)) {
      lst_push_ptr(retval, t_cur);     /* hand ownership to retval */
      /* duplicate the pointer intentionally (MCMC samples can repeat) */
      kept++;
      if (kept == nsamples) break;
    }

    /* light diagnostics */
    if (it % 1000 == 0 || it == burn_keep) {
      double acc_rate = (try_burn > 0 ? (double)acc_burn / (double)try_burn : 0.0);
      fprintf(stderr, "# pCN it=%d/%d  rho=%.3f  burn_acc=%.3f  LNL=%.3f\n",
              it, iters_needed, rho, acc_rate, lnl_cur);
    }
  }

  /* If early stop (kept==nsamples), OK. Otherwise fill with last state copies */
  while (kept < nsamples) { lst_push_ptr(retval, t_cur); kept++; }

  /* cleanup (do not free trees in retval) */
  vec_free(points_x);
  vec_free(points_y);
  vec_free(points_z);
  vec_free(nu_x);
  vec_free(nu_z);
  sfree(x_cur);
  sfree(x_prop);

  fprintf(stderr, "# pCN done: kept=%d, rho_final=%.3f\n", kept, rho);
  return retval;
}

/* ===== Blocked pCN MCMC with occasional independence refreshes (TreeNode*) ==
   - Prior: x ~ mmvn
   - Blocked pCN proposal on a random subset B of coordinates:
       x'_B = sqrt(1-rho^2) * x_B + rho * nu_B,   nu ~ mmvn
       x'_{¬B} = x_{¬B}
     This preserves the prior exactly; acceptance depends only on likelihood.
   - With small prob p_refresh, propose an independence draw x' ~ mmvn.
   - Robbins–Monro adaptation of rho during burn-in, bounded away from 0.

   Returns nsamples trees (duplicates possible; MCMC).
   Diagnostics printed to stderr.
============================================================================= */

static inline void shuffle_prefix(int *idx, int n, int k) {
  /* Fisher–Yates partial shuffle: randomize first k positions of idx[0..n-1] */
  for (int i = 0; i < k; ++i) {
    int j = i + (int)floor(unif_rand() * (double)(n - i));
    if (j < i) j = i;
    if (j >= n) j = n - 1;
    int t = idx[i]; idx[i] = idx[j]; idx[j] = t;
  }
}

List *nj_var_sample_pcn_blocked(int nsamples, multi_MVN *mmvn,
                                CovarData *data, TreeModel *mod,
                                FILE *logf /* unused; diagnostics -> stderr */)
{
  /* ---- knobs (tweak here) ---------------------------------------------- */
  const double block_frac   = 0.05;  /* fraction of dims to update per step (1–10% is typical) */
  const int    min_block    = 4;     /* at least this many coordinates in a block              */
  const int    thin         = 5;     /* keep 1 every 'thin' steps after burn-in                */
  const int    burn_keep    = 3000;  /* burn-in steps (not kept)                               */
  const double rho_init     = 0.35;  /* initial step size (0<rho<1)                            */
  const double acc_target   = 0.30;  /* target acceptance during burn-in                       */
  const double adapt_gain   = 0.05;  /* adaptation step gain (small to avoid oscillations)     */
  const double rho_min      = 0.02;  /* do not let rho collapse to 0                           */
  const double rho_max      = 0.95;  /* cap                                                    */
  const double p_refresh    = 0.02;  /* probability of a full MVN independence proposal        */
  /* ---------------------------------------------------------------------- */

  int dim = mmvn->d * mmvn->n;
  int block_size = (int)floor(block_frac * dim);
  if (block_size < min_block) block_size = min_block;
  if (block_size > dim) block_size = dim;

  /* total iterations = burn + kept*thin */
  int iters_needed = burn_keep + nsamples * thin;

  List *retval = lst_new_ptr(nsamples);

  Vector *points_x = vec_new(dim);
  Vector *points_y = vec_new(dim);
  Vector *points_z = vec_new(dim);   /* only used for sampling */

  /* current and proposal parameter vectors (x space) */
  double *x_cur  = (double*)smalloc((size_t)dim * sizeof(double));
  double *x_prop = (double*)smalloc((size_t)dim * sizeof(double));
  double *nu_buf = (double*)smalloc((size_t)dim * sizeof(double)); /* to hold a fresh MVN draw */

  /* indices 0..dim-1 (for partial shuffles) */
  int *idx = (int*)smalloc((size_t)dim * sizeof(int));
  for (int d = 0; d < dim; ++d) idx[d] = d;

  double logdet, lnl_cur, lnl_prop;

  /* --- initialize state from prior --- */
  {
    do {
      nj_sample_points(mmvn, points_x, points_z);                /* x ~ mmvn */
      nj_apply_normalizing_flows(points_y, points_x, data, &logdet);
      nj_points_to_distances(points_y, data);
      mod->tree = nj_inf(data->dist, data->names, NULL, data);

      if (data->crispr_mod != NULL) lnl_cur = cpr_compute_log_likelihood(data->crispr_mod, NULL);
      else                          lnl_cur = nj_compute_log_likelihood(mod, data, NULL);

      if (!isfinite(lnl_cur) || !isfinite(logdet)) tr_free(mod->tree);
    } while (!isfinite(lnl_cur) || !isfinite(logdet));

    for (int d = 0; d < dim; ++d) x_cur[d] = vec_get(points_x, d);
  }
  TreeNode *t_cur = mod->tree;

  /* proposal scratch vectors */
  Vector *nu_x = vec_new(dim), *nu_z = vec_new(dim);

  /* adaptation state */
  double rho = rho_init;
  int acc_burn = 0, try_burn = 0;

  int kept = 0;
  for (int it = 1; it <= iters_needed; ++it) {

    int independence_move = (unif_rand() < p_refresh) ? 1 : 0;

    if (independence_move) {
      /* x_prop := full MVN draw */
      nj_sample_points(mmvn, points_x, points_z);
      for (int d = 0; d < dim; ++d) x_prop[d] = vec_get(points_x, d);
    } else {
      /* blocked pCN step: draw a fresh nu ~ mmvn, then blend only a subset */
      nj_sample_points(mmvn, nu_x, nu_z);
      for (int d = 0; d < dim; ++d) nu_buf[d] = vec_get(nu_x, d);

      /* pick a random block of size block_size */
      shuffle_prefix(idx, dim, block_size);

      /* x_prop := x_cur initially */
      for (int d = 0; d < dim; ++d) x_prop[d] = x_cur[d];

      /* update only the chosen block with pCN */
      double a = sqrt(fmax(0.0, 1.0 - rho*rho));
      for (int j = 0; j < block_size; ++j) {
        int d = idx[j];
        x_prop[d] = a * x_cur[d] + rho * nu_buf[d];
      }
    }

    /* evaluate proposed tree likelihood */
    for (int d = 0; d < dim; ++d) vec_set(points_x, d, x_prop[d]);
    nj_apply_normalizing_flows(points_y, points_x, data, &logdet);
    nj_points_to_distances(points_y, data);
    TreeNode *t_prop = nj_inf(data->dist, data->names, NULL, data);

    if (data->crispr_mod != NULL) lnl_prop = cpr_compute_log_likelihood(data->crispr_mod, NULL);
    else                          lnl_prop = nj_compute_log_likelihood(mod, data, NULL);

    int accept = 0;
    if (isfinite(lnl_prop) && isfinite(logdet)) {
      /* Prior cancels for both the blocked pCN and independence moves
         because proposals are formed from the prior. */
      double log_alpha = lnl_prop - lnl_cur;
      double u = log(unif_rand());
      if (u < log_alpha) accept = 1;
    }

    if (it <= burn_keep) { try_burn++; if (accept) acc_burn++; }

    if (accept) {
      for (int d = 0; d < dim; ++d) x_cur[d] = x_prop[d];
      tr_free(t_cur);
      t_cur = t_prop;
      lnl_cur = lnl_prop;
      mod->tree = t_cur;
    } else {
      tr_free(t_prop);
      mod->tree = t_cur;
    }

    /* adapt rho during burn-in (bounded; do NOT let it go to 0) */
    if (!independence_move && it <= burn_keep) {
      double adj = ((accept) ? 1.0 : 0.0) - acc_target;
      rho += adapt_gain * adj;
      if (rho < rho_min) rho = rho_min;
      if (rho > rho_max) rho = rho_max;
    }

    /* keep (thinned) post-burn-in samples */
    if (it > burn_keep && ((it - burn_keep) % thin == 0)) {
      lst_push_ptr(retval, t_cur);   /* store pointer; OK to repeat */
      kept++;
      if (kept == nsamples) break;
    }

    if (it % 1000 == 0 || it == burn_keep) {
      double acc_rate = (try_burn > 0 ? (double)acc_burn / (double)try_burn : 0.0);
      fprintf(stderr,
        "# pCN(blocked) it=%d/%d  rho=%.3f  burn_acc=%.3f  block=%d  refresh=%d  LNL=%.3f\n",
        it, iters_needed, rho, acc_rate, block_size, independence_move, lnl_cur);
    }
  }

  while (kept < nsamples) { lst_push_ptr(retval, t_cur); kept++; }

  /* cleanup */
  vec_free(points_x);
  vec_free(points_y);
  vec_free(points_z);
  vec_free(nu_x);
  vec_free(nu_z);
  sfree(x_cur);
  sfree(x_prop);
  sfree(nu_buf);
  sfree(idx);

  fprintf(stderr, "# pCN(blocked) done: kept=%d, rho_final=%.3f, block=%d, p_refresh=%.3f\n",
          nsamples, rho, block_size, p_refresh);
  return retval;
}

/* =========================================================================
   Parallel Tempering (Metropolis-coupled) with blocked pCN local moves
   - Ladders inverse temperatures beta[0]=1.0 > beta[1] > ... > beta[L-1]
   - Each chain uses blocked pCN proposals (prior-preserving).
   - Periodic neighbor swaps move states across temperatures.
   - Only samples from the cold chain (beta=1) are returned.

   Author: drop-in sibling for your sampling code (TreeNode*).
   Prints diagnostics to stderr; 'logf' is unused here.
   ======================================================================== */

static inline void pt_shuffle_prefix(int *idx, int n, int k) {
  /* partial Fisher–Yates: randomize first k positions */
  for (int i = 0; i < k; ++i) {
    int j = i + (int)floor(unif_rand() * (double)(n - i));
    if (j < i) j = i;
    if (j >= n) j = n - 1;
    int t = idx[i]; idx[i] = idx[j]; idx[j] = t;
  }
}

List *nj_var_sample_pcn_pt(int nsamples, multi_MVN *mmvn,
                           CovarData *data, TreeModel *mod,
                           FILE *logf /* unused; diagnostics -> stderr */)
{
  /* ---------------- knobs (feel free to tune) ---------------- */
  const int    L          = 6;      /* number of chains in ladder (4–8 typical) */
  const double beta_top   = 1.0;    /* cold chain */
  const double beta_bot   = 0.20;   /* hottest chain (smaller => flatter) */
  const double block_frac = 0.06;   /* fraction of dims updated per pCN step */
  const int    min_block  = 4;      /* minimum coords per update */
  const double rho_init   = 0.25;   /* pCN step size for all chains */
  const double rho_min    = 0.02;   /* don’t let it collapse */
  const double rho_max    = 0.95;
  const double acc_target = 0.25;   /* per-chain burn-in target acceptance */
  const double adapt_gain = 0.05;   /* Robbins–Monro gain (burn-in only) */
  const double p_refresh  = 0.02;   /* occasional independence draw */
  const int    thin       = 5;      /* thin cold-chain samples */
  const int    burn_steps = 6000;   /* total burn-in iterations */
  const int    swap_every = 25;     /* attempt neighbor swaps every N iters */
  /* ----------------------------------------------------------- */

  int dim = mmvn->d * mmvn->n;
  int block_size = (int)floor(block_frac * dim);
  if (block_size < min_block) block_size = min_block;
  if (block_size > dim) block_size = dim;

  /* geometric ladder in inverse temperature space */
  double beta[L];
  for (int l = 0; l < L; ++l) {
    double t = (L==1)?0.0 : (double)l/(double)(L-1);
    /* geometric in temperature => linear in log beta */
    double logb = log(beta_top) + t*(log(beta_bot) - log(beta_top));
    beta[l] = exp(logb);
  }
  beta[0] = 1.0; /* ensure exact 1.0 */
  if (beta[L-1] > beta[0]) beta[L-1] = beta[0]; /* safety */

  /* total iterations needed after burn to collect nsamples with thinning */
  int keep_needed = nsamples;
  int iters_after_burn = keep_needed * thin;
  int iters_total = burn_steps + iters_after_burn;

  List *retval = lst_new_ptr(nsamples);

  /* per-chain state */
  Vector *xV[L], *yV[L], *zV[L], *nuV[L], *nuzV[L];
  double *x[L];                 /* raw array view of xV for easy editing */
  double lnl[L];                /* current log-likelihood per chain */
  TreeNode *tree[L];            /* current tree per chain */
  double rho[L];                /* pCN step size per chain (adapt in burn) */
  int    acc_cnt[L];            /* accept counter in burn for diagnostics */
  int    try_cnt[L];            /* trial counter in burn */

  /* scratch */
  int *idx = (int*)smalloc((size_t)dim * sizeof(int));
  for (int d = 0; d < dim; ++d) idx[d] = d;

  /* init vectors and step sizes */
  for (int l = 0; l < L; ++l) {
    xV[l]   = vec_new(dim);
    yV[l]   = vec_new(dim);
    zV[l]   = vec_new(dim);
    nuV[l]  = vec_new(dim);
    nuzV[l] = vec_new(dim);
    x[l]    = (double*)smalloc((size_t)dim * sizeof(double));
    rho[l]  = rho_init;
    acc_cnt[l] = 0; try_cnt[l] = 0;
  }

  /* initialize each chain from the prior (independence draw) */
  for (int l = 0; l < L; ++l) {
    double logdet;
    double lnl_here;
    do {
      nj_sample_points(mmvn, xV[l], zV[l]);
      nj_apply_normalizing_flows(yV[l], xV[l], data, &logdet);
      nj_points_to_distances(yV[l], data);
      mod->tree = nj_inf(data->dist, data->names, NULL, data);

      if (data->crispr_mod != NULL) lnl_here = cpr_compute_log_likelihood(data->crispr_mod, NULL);
      else                          lnl_here = nj_compute_log_likelihood(mod, data, NULL);

      if (!isfinite(lnl_here) || !isfinite(logdet)) tr_free(mod->tree);
    } while (!isfinite(lnl_here) || !isfinite(logdet));

    for (int d = 0; d < dim; ++d) {
      x[l][d] = vec_get(xV[l], d);
      vec_set(xV[l], d, x[l][d]);
    }
    tree[l] = mod->tree;
    lnl[l]  = lnl_here;
  }

  int kept = 0;
  for (int it = 1; it <= iters_total; ++it) {
    /* ===== local moves (each chain, in parallel loop) ===== */
    for (int l = 0; l < L; ++l) {
      int independence_move = (unif_rand() < p_refresh) ? 1 : 0;

      /* build proposal into xV[l] (reuse as prop container), evaluate lnl_prop */
      double logdet;
      if (independence_move) {
        nj_sample_points(mmvn, xV[l], zV[l]); /* full draw: prior-preserving */
      } else {
        /* blocked pCN: x_prop_B = a*x_B + rho*nu_B; x_prop_¬B = x_¬B */
        nj_sample_points(mmvn, nuV[l], nuzV[l]);      /* nu ~ prior */
        pt_shuffle_prefix(idx, dim, block_size);      /* choose coordinates */
        double a = sqrt(fmax(0.0, 1.0 - rho[l]*rho[l]));
        /* start prop as current x */
        for (int d = 0; d < dim; ++d) vec_set(xV[l], d, x[l][d]);
        for (int j = 0; j < block_size; ++j) {
          int d = idx[j];
          double cur = x[l][d];
          double nu  = vec_get(nuV[l], d);
          vec_set(xV[l], d, a*cur + rho[l]*nu);
        }
      }

      nj_apply_normalizing_flows(yV[l], xV[l], data, &logdet);
      nj_points_to_distances(yV[l], data);
      TreeNode *t_prop = nj_inf(data->dist, data->names, NULL, data);

      double lnl_prop;
      if (data->crispr_mod != NULL) lnl_prop = cpr_compute_log_likelihood(data->crispr_mod, NULL);
      else                          lnl_prop = nj_compute_log_likelihood(mod, data, NULL);

      int accept = 0;
      if (isfinite(lnl_prop) && isfinite(logdet)) {
        /* prior cancels; tempered target => accept on beta[l]*(Δloglik) */
        double log_alpha = beta[l] * (lnl_prop - lnl[l]);
        if (log(unif_rand()) < log_alpha) accept = 1;
      }

      if (it <= burn_steps) { try_cnt[l]++; if (accept) acc_cnt[l]++; }

      if (accept) {
        /* commit */
        for (int d = 0; d < dim; ++d) x[l][d] = vec_get(xV[l], d);
        tr_free(tree[l]);
        tree[l] = t_prop;
        lnl[l]  = lnl_prop;
        mod->tree = tree[l];
      } else {
        tr_free(t_prop);
        /* restore xV[l] to current x to keep vectors consistent */
        for (int d = 0; d < dim; ++d) vec_set(xV[l], d, x[l][d]);
        mod->tree = tree[l];
      }

      /* simple bounded adaptation during burn-in only (skip if independence) */
      if (!independence_move && it <= burn_steps) {
        double adj = ((accept)?1.0:0.0) - acc_target;
        rho[l] += adapt_gain * adj;
        if (rho[l] < rho_min) rho[l] = rho_min;
        if (rho[l] > rho_max) rho[l] = rho_max;
      }
    }

    /* ===== neighbor swaps (every swap_every iters) ===== */
    if (it % swap_every == 0) {
      for (int l = 0; l < L-1; ++l) {
        /* swap proposal between chains l and l+1 */
        int i = l, j = l+1;
        /* acceptance for states (x_i, x_j) under betas (β_i, β_j):
           α = min(1, exp((β_i-β_j) * (lnl_j - lnl_i))) */
        double d = (beta[i] - beta[j]) * (lnl[j] - lnl[i]);
        int do_swap = (log(unif_rand()) < d) ? 1 : 0;
        if (do_swap) {
          /* swap x arrays */
          for (int d0 = 0; d0 < dim; ++d0) {
            double tmp = x[i][d0]; x[i][d0] = x[j][d0]; x[j][d0] = tmp;
          }
          /* reflect x into xV to keep consistent */
          for (int d0 = 0; d0 < dim; ++d0) { vec_set(xV[i], d0, x[i][d0]); vec_set(xV[j], d0, x[j][d0]); }
          /* swap trees (ownership) and logliks */
          TreeNode *tt = tree[i]; tree[i] = tree[j]; tree[j] = tt;
          double    ll = lnl[i];  lnl[i]  = lnl[j];  lnl[j]  = ll;
        }
      }
    }

    /* ===== record from cold chain after burn, with thinning ===== */
    if (it > burn_steps) {
      int k = it - burn_steps;
      if (k % thin == 0) {
        /* Duplicate the TreeNode pointer (store current pointer) */
        lst_push_ptr(retval, tree[0]);
        kept++;
        if (kept == nsamples) break;
      }
    }

    /* periodic diagnostics */
    if (it % 1000 == 0 || it == burn_steps) {
      double acc0 = (try_cnt[0] > 0 ? (double)acc_cnt[0]/(double)try_cnt[0] : 0.0);
      fprintf(stderr, "# PT it=%d/%d  cold_rho=%.3f  cold_burn_acc=%.3f  LNL0=%.3f  betas:",
              it, iters_total, rho[0], acc0, lnl[0]);
      for (int l = 0; l < L; ++l) fprintf(stderr, " %.2f", beta[l]);
      fprintf(stderr, "\n");
    }
  }

  /* If we somehow didn’t fill (shouldn’t happen), pad with last cold tree */
  while (kept < nsamples) { lst_push_ptr(retval, tree[0]); kept++; }

  /* free: do NOT free the trees we returned pointers to.
     We only free the trees in hot chains we won’t return. */
  for (int l = 1; l < L; ++l) tr_free(tree[l]);
  /* cold tree (tree[0]) is owned by retval list now */

  for (int l = 0; l < L; ++l) {
    vec_free(xV[l]); vec_free(yV[l]); vec_free(zV[l]); vec_free(nuV[l]); vec_free(nuzV[l]);
    sfree(x[l]);
  }
  sfree(idx);

  fprintf(stderr, "# PT done: kept=%d (thin=%d), L=%d, block=%d, rho0=%.3f..%.3f\n",
          nsamples, thin, L, block_size, rho[0], rho[L-1]);
  return retval;
}
