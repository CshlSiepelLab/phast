/* experimental resampling routines for refining samples from
   variational distribution.  Some of this code is generated by
   chatGPT */

#include <stdio.h>
#include <stdlib.h>
#include <ctype.h>
#include <assert.h>
#include <float.h>
#include "phast/misc.h"
#include "phast/nj.h"
#include "phast/mvn.h"
#include "phast/multi_mvn.h"
#include "phast/trees.h"

/* subsample from a set of trees by importance sampling, using ratio
   of likelihoods to sampling density as weights.  Warning: tree
   objects in returned list will be shared with those in primary list
   and may repeat */
List *nj_importance_sample(int nsamples, List *trees, Vector *logdens,
                           TreeModel *mod, CovarData *data, FILE *logf) {
  List *retval = lst_new_ptr(nsamples);
  Vector *weights = vec_new(lst_size(trees));
  Vector *lls = vec_new(lst_size(trees));
  double ll, maxll = -INFTY, maxweight = -INFTY, sampll = 0;
  int i, count = 0;

  if (logdens->size != lst_size(trees))
    die("ERROR in nj_importance_sample: bad input.\n");
  
  /* calculate importance weights from likelihoods */
  for (i = 0; i < lst_size(trees); i++) {
    TreeNode *t = lst_get_ptr(trees, i);    
    mod->tree = t;
    ll = nj_compute_log_likelihood(mod, data, NULL);
    if (!isfinite(ll))  /* can happen with crispr model */
      ll = -INFTY;
    if (ll > maxll) maxll = ll;
    vec_set(lls, i, ll);
    ll -= vec_get(logdens, i);
    vec_set(weights, i, ll);
    if (ll > maxweight) maxweight = ll;
  }
  assert(maxweight > -INFTY);

  /* exponentiate and renormalize */
  for (i = 0; i < lst_size(trees); i++) {
    ll = vec_get(weights,i);
    vec_set(weights, i, exp(ll-maxweight));  /* avoids underflow */
  }
  pv_normalize(weights);

  for (i = 0; i < lst_size(trees); i++) 
    if (vec_get(weights, i) > 1.0/(lst_size(trees)*10))
      count++;

  if (count < nsamples)
    fprintf(stderr, "Warning: only %d trees eligible for importance sampling...\n", count);
    
  /* now draw nsamples */
  for (i = 0; i < nsamples; i++) {
    int j = pv_draw_idx(weights);
    assert(j >= 0 && j < lst_size(trees));
    lst_push_ptr(retval, lst_get_ptr(trees, j));
    sampll += vec_get(lls, j);
  }

  if (logf != NULL)
    fprintf(logf, "# Importance sampling from %d eligible trees of %d; avelnl: %f, maxlnl: %f\n",
            count, lst_size(trees), sampll/nsamples, maxll);

  vec_free(weights);
  vec_free(lls);
  
  return(retval);
}

/* for use below -- looks up region corresponding given value of z^2 using binary search */
static inline int get_region(Vector *quants, double z2) {
    int lo = 0, hi = quants->size - 1; 
    while (lo + 1 < hi) {
        int mid = (lo + hi) >> 1;
        if (z2 < vec_get(quants, mid))
          hi = mid;
        else
          lo = mid;
    }
    return lo; 
}

/* Like nj_var_sample, but use rejection sampling to sharpen the
   approximate posterior.  Divides sampling distribution into regions
   ("shells") based on distance from mean. Recalibrates region by
   region if envelope violations occur.  Has a number of other
   optimizations to improve acceptance rate and efficiency, but
   overall rate still tends to be low in many cases. */
List *nj_var_sample_rejection(int nsamples, multi_MVN *mmvn,
                              CovarData *data, TreeModel *mod,
                              FILE *logf) {
  int nprop = max(nsamples * 10, 2000);
  int dim = mmvn->d * mmvn->n;
  int nreg = 12; /* number of regions into which to partition sampling space */
  const double q_center = 0.990; /* inner shells */
  const double q_tail   = 0.9990;/* outer shells */
  const double m_center = 0.35;  /* inner shells margin */
  const double m_tail   = 0.60;  /* outer shells margin */
  const double delta_min = 0.25;   /* minimum bump on violation (log-space) */
  const double tail_frac = 0.20;  /* top fraction used to estimate tail spread */
  const int    tail_nmin = 20;    /* minimum tail sample size per region */
  const double gap_gain  = 1.05;  /* scales observed gap in bump */
  const double bump_gain = 1.60;  /* geometric escalation per repeated violation */
  List *retval = lst_new_ptr(nsamples), *init_samples = lst_new_ptr(nprop);
  Vector *points_x = vec_new(dim), *points_z = vec_new(dim),
    *points_y = vec_new(dim), *quants;
  double lnl, mvnl, logu, z2, avelnl = 0, logdet;
  double *ll, *mvnll, *logM, *sigma_tail;
  int i, ntot, r;
  int *reg, *regnum, *accpt;
  unsigned int *retained;
  int *viol_count;
  int *since_viol;    /* proposals since last violation in this region */
  const int cooldown_trigger = 200;  /* proposals (any shells) between decays */
  const int cooldown_step = 1;    /* how much to reduce viol_count on cooldown */
 
  /* per-accepted-sample metadata for region-specific revalidation */
  int    *acc_region = smalloc(nsamples * sizeof(int));
  double *acc_logu = smalloc(nsamples * sizeof(double));
  double *acc_logr = smalloc(nsamples * sizeof(double));
  double *acc_ll = smalloc(nsamples * sizeof(double));  /* for avelnl repair */
  
  ll = smalloc(nprop * sizeof(double));
  mvnll = smalloc(nprop * sizeof(double));
  logM = smalloc(nreg * sizeof(double));
  sigma_tail = smalloc(nreg * sizeof(double));
  reg = smalloc(nprop * sizeof(int));
  retained = smalloc(nprop * sizeof(unsigned int));
  regnum = smalloc(nreg * sizeof(int));
  accpt = smalloc(nreg * sizeof(int));
  viol_count = smalloc(nreg * sizeof(int));
  since_viol = smalloc(nreg * sizeof(int));
  
  for (r = 0; r < nreg; r++) {
    logM[r] = -INFTY; regnum[r] = 0; accpt[r] = 0;
    viol_count[r] = 0; since_viol[r] = 0;
  }
  
  /* preprocessing step to partition sampling space into equally sized
     regions, with one bound per region.  Use the fact that the
     initial standard MVN variable z is such that z^2 is chisq
     distributed with d d.o.f.  We can therefore partition based on
     the quantiles of the chisq distribution */

  quants = vec_new(nreg+1);
  vec_set(quants, 0, 0);
  for (r = 1; r < nreg; r++)
    vec_set(quants, r, chisq_cdf_inv((double)r / nreg, dim));
  vec_set(quants, nreg, INFINITY);
  /* ith quantile ranges from quants[i] to quants[i+1], with i ranging from 0 to nreg-1 */

 
  /* collect an initial sample to approximate the upper bounds on the
     log ratio of densities */
  for (i = 0; i < nprop; i++) {
    do {
      nj_sample_points(mmvn, points_x, points_z);
      nj_apply_normalizing_flows(points_y, points_x, data, &logdet);
      nj_points_to_distances(points_y, data);
      mod->tree = nj_inf(data->dist, data->names, NULL, data);

      if (data->crispr_mod != NULL)
        ll[i] = cpr_compute_log_likelihood(data->crispr_mod, NULL);
      else
        ll[i] = nj_compute_log_likelihood(mod, data, NULL);

      if (!isfinite(ll[i]) || !isfinite(logdet)) tr_free(mod->tree);
    } while (!isfinite(ll[i]) || !isfinite(logdet));  
    
    lst_push_ptr(init_samples, mod->tree);
    mvnll[i] = mmvn_log_dens(mmvn, points_x) - logdet;   /* note logdet jacobian for flows */

    /* find region corresponding to quantile */
    z2 = vec_inner_prod(points_z, points_z);
    reg[i] = get_region(quants, z2);
    regnum[reg[i]]++;      
  }

 /* set per-region envelopes from pilot quantiles */
  List *tmp = lst_new_dbl(nprop);
  for (r = 0; r < nreg; r++) {
    lst_clear(tmp);
    if (regnum[r] <= 0) { logM[r] = -INFTY; continue; }  /* safety: should not happen */
    for (i = 0; i < nprop; i++) if (reg[i] == r) lst_push_dbl(tmp, ll[i] - mvnll[i]);
    lst_qsort_dbl(tmp, ASCENDING);
    int m = lst_size(tmp);
    double t = (double)r / (double)(nreg - 1);               /* 0..1 from inner->outer */
    double q_r = q_center + t * (q_tail - q_center);         /* interpolate quantile */
    double mg  = m_center + t * (m_tail - m_center);         /* interpolate margin  */
    if (q_r > 0.9999) q_r = 0.9999;                          /* clamp */
    int idx = (int) floor(q_r * (double)(m - 1));
    logM[r] = lst_get_dbl(tmp, idx) + mg;   /* per-shell quantile + margin */
    /* estimate tail spread sigma_tail[r] from top tail_frac (>= tail_nmin) */
    int tail_n = (int) (tail_frac * m);
    if (tail_n < tail_nmin) tail_n = tail_nmin;
    if (tail_n > m) tail_n = m;
    /* compute unbiased SD over the top tail_n values */
    double mean = 0.0, var = 0.0, x;
    for (i = m - tail_n; i < m; i++) { x = lst_get_dbl(tmp, i); mean += x; }
    mean /= (double)tail_n;
    for (i = m - tail_n; i < m; i++) { x = lst_get_dbl(tmp, i); double d = x - mean; var += d*d; }
    sigma_tail[r] = (tail_n > 1) ? sqrt(var / (double)(tail_n - 1)) : 0.0;
  }
  lst_free(tmp);

  /* light smoothing: enforce nondecreasing logM and sigma_tail across shells */
  for (r = 1; r < nreg; ++r) {
    if (logM[r] < logM[r-1]) logM[r] = logM[r-1];
    if (sigma_tail[r] < sigma_tail[r-1]) sigma_tail[r] = sigma_tail[r-1];
  }
  
  /* subsample from initial set by rejection sampling */

  for (i = 0; i < lst_size(init_samples); i++)
    retained[i] = FALSE; /* init */
    
  for (i = 0; i < lst_size(init_samples) &&
         lst_size(retval) < nsamples; i++) {
    logu = log(unif_rand());
    if (logu <= ll[i] - mvnll[i] - logM[reg[i]]) {
      int idx = lst_size(retval);
      lst_push_ptr(retval, lst_get_ptr(init_samples, i));
      retained[i] = TRUE;
      avelnl += ll[i];

      /* record acceptance metadata for region-specific revalidation */
      acc_region[idx] = reg[i];
      acc_logu[idx] = logu;
      acc_logr[idx] = ll[i] - mvnll[i];
      acc_ll[idx] = ll[i];
    }
  }
  ntot = i; /* total number examined */

  for (r = 0; r < nreg; r++) accpt[r] = 0;
  for (int j = 0; j < lst_size(retval); ++j) accpt[acc_region[j]]++;
  fprintf(stderr, "region-specific acceptance rates (overall %f): ",
          lst_size(retval)/(double)ntot);
  for (r = 0; r < nreg; r++)
    fprintf(stderr, "%d (%f) ", r, regnum[r] ? (double)accpt[r]/regnum[r] : 0.0);
  fprintf(stderr, "\n");
 
  /* check to see whether it is feasible to go forward */
  double init_acrt = lst_size(retval)/(double)ntot;
  if (init_acrt < 0.001)
    die("ERROR in nj_var_sample_rejection: acceptance rate %f too low.  Aborting.\n",
        init_acrt);

  /* if necessary, continue until target is met */
  while (lst_size(retval) < nsamples) {
    ntot++;
    do {
      nj_sample_points(mmvn, points_x, points_z);
      nj_apply_normalizing_flows(points_y, points_x, data, &logdet);
      nj_points_to_distances(points_y, data);
      mod->tree = nj_inf(data->dist, data->names, NULL, data);

      if (data->crispr_mod != NULL)
        lnl = cpr_compute_log_likelihood(data->crispr_mod, NULL);
      else
        lnl = nj_compute_log_likelihood(mod, data, NULL);

      if (!isfinite(lnl) || !isfinite(logdet)) tr_free(mod->tree);
    } while (!isfinite(lnl) || !isfinite(logdet)); 
    
    mvnl = mmvn_log_dens(mmvn, points_x) - logdet;
    z2 = vec_inner_prod(points_z, points_z);
    r = get_region(quants, z2);

    /* cooldown bookkeeping: count quiet proposals per region */
    for (int rr = 0; rr < nreg; ++rr) if (rr != r) since_viol[rr]++;
    since_viol[r] = 0;
    if (lnl - mvnl > logM[r]) { /* envelope violation: region-specific repair */
      double logr_new = lnl - mvnl;
      double gap = logr_new - logM[r];
      double base_bump = fmax(delta_min, fmax(2.0 * sigma_tail[r], gap_gain * gap));
      double bump = base_bump * pow(bump_gain, (double)viol_count[r]);
      viol_count[r]++;
      double new_logM = logr_new + bump;
      fprintf(stderr,
              "Region %d exceeded by %.6f (%.6f - %.6f): bump=%.3f (σ=%.3f, nviol=%d); revalidating region...\n",
              r, gap, logr_new, logM[r], bump, sigma_tail[r], viol_count[r]);
      logM[r] = new_logM;
      /* revalidate ONLY accepted samples from region r */
      List *new_ret = lst_new_ptr(nsamples);
      int new_n = 0;
      double new_avelnl = 0.0;
      for (int j = 0; j < lst_size(retval); ++j) {
        if (acc_region[j] != r) {
          /* keep sample from other regions */
          lst_push_ptr(new_ret, lst_get_ptr(retval, j));
          acc_region[new_n] = acc_region[j];
          acc_logu[new_n] = acc_logu[j];
          acc_logr[new_n] = acc_logr[j];
          acc_ll[new_n] = acc_ll[j];
          new_avelnl += acc_ll[j];
          new_n++;
          continue;
        }
        /* same region: keep only if still passing with updated logM[r] */
        if (acc_logu[j] <= acc_logr[j] - new_logM) {
          lst_push_ptr(new_ret, lst_get_ptr(retval, j));
          acc_region[new_n] = acc_region[j];
          acc_logu[new_n]   = acc_logu[j];
          acc_logr[new_n]   = acc_logr[j];
          acc_ll[new_n]     = acc_ll[j];
          new_avelnl       += acc_ll[j];
          new_n++;
        }
        else 
          /* drop invalid sample */
          tr_free(lst_get_ptr(retval, j));
      }
      /* swap in rebuilt accepted set */
      lst_free(retval);
      retval = new_ret;
      avelnl = new_avelnl;
      /* cooldown: let quiet regions relax their escalation */
      for (int rr = 0; rr < nreg; ++rr) {
        if (since_viol[rr] >= cooldown_trigger && viol_count[rr] > 0) {
          viol_count[rr] = (viol_count[rr] > cooldown_step) ? (viol_count[rr] - cooldown_step) : 0;
          since_viol[rr] = 0;
        }
      }
      /* discard the current (violating) proposal and continue */
      tr_free(mod->tree);
      continue;  /* do not restart; keep sampling */
    }

    logu = log(unif_rand());
    if (logu <= lnl - mvnl - logM[r]) {
      int idx = lst_size(retval);
      lst_push_ptr(retval, mod->tree);
      avelnl += lnl;
      
      /* record acceptance metadata */
      acc_region[idx] = r;
      acc_logu[idx] = logu;
      acc_logr[idx] = lnl - mvnl;
      acc_ll[idx] = lnl;
    }
    else
      tr_free(mod->tree);

    /* cooldown tick also on non-violating iterations */
    for (int rr = 0; rr < nreg; ++rr) {
      if (since_viol[rr] >= cooldown_trigger && viol_count[rr] > 0) {
        viol_count[rr] = (viol_count[rr] > cooldown_step) ? (viol_count[rr] - cooldown_step) : 0;
        since_viol[rr] = 0;
      }
    }
  }
  
  /* free any trees not used from initial set */
  for (i = 0; i < lst_size(init_samples); i++)
    if (retained[i] == FALSE)
      tr_free(lst_get_ptr(init_samples, i));

  if (logf != NULL)
    fprintf(logf, "# Rejection sampling from %d trees (acceptance rate %.3f); avelnl: %f\n",
            ntot, nsamples*1.0/ntot, avelnl/nsamples);
  
  lst_free(init_samples);
  vec_free(points_x);
  vec_free(points_y);
  vec_free(points_z);
  vec_free(quants);
  sfree(ll);
  sfree(mvnll);
  sfree(logM);
  sfree(sigma_tail);
  sfree(reg);
  sfree(retained);
  sfree(regnum);
  sfree(accpt);
  sfree(viol_count);
  sfree(since_viol);
  sfree(acc_region);
  sfree(acc_logu);
  sfree(acc_logr);
  sfree(acc_ll);
  return(retval);
}

/* Like nj_var_sample_rejection, but do shell-aware importance sampling
   with systematic resampling to return exactly nsamples trees. */
List *nj_var_sample_importance(int nsamples, multi_MVN *mmvn,
                               CovarData *data, TreeModel *mod,
                               FILE *logf) {
  int nprop = max(nsamples * 20, 20000);   
  int dim   = mmvn->d * mmvn->n;
  int nreg  = 12; 
  /* const double q_center = 0.990; /\* inner shells *\/ */
  /* const double q_tail   = 0.9990;/\* outer shells *\/ */

  /* outputs & workspaces */
  List *retval = lst_new_ptr(nsamples);
  List *props  = lst_new_ptr(nprop);

  Vector *points_x = vec_new(dim), *points_z = vec_new(dim),
    *points_y = vec_new(dim), *quants;

  /* per-proposal storage */
  double *logw = smalloc(nprop * sizeof(double));   /* log-weights = ll - mvnll */
  double *ll   = smalloc(nprop * sizeof(double));   /* (optional) diagnostics */
  double *mvnll = smalloc(nprop * sizeof(double));
  int *shell = smalloc(nprop * sizeof(int));

  /* shell diagnostics */
  int *regnum = smalloc(nreg * sizeof(int));
  for (int r = 0; r < nreg; ++r) regnum[r] = 0;

  /* build chi^2 shell boundaries */
  quants = vec_new(nreg + 1);
  vec_set(quants, 0, 0);
  for (int r = 1; r < nreg; r++)
    vec_set(quants, r, chisq_cdf_inv((double)r / nreg, dim));
  vec_set(quants, nreg, INFINITY);

  /* Proposal phase: draw nprop, compute log-weights */
  double logdet, z2, max_logw = -INFTY, lnl, mvnl;
  for (int i = 0; i < nprop; ++i) {
    /* draw from q(x) (MVN in whitened space), map through flow, infer tree, eval ll */
    do {
      nj_sample_points(mmvn, points_x, points_z);
      nj_apply_normalizing_flows(points_y, points_x, data, &logdet);
      nj_points_to_distances(points_y, data);
      mod->tree = nj_inf(data->dist, data->names, NULL, data);

      if (data->crispr_mod != NULL)
        lnl = cpr_compute_log_likelihood(data->crispr_mod, NULL);
      else
        lnl = nj_compute_log_likelihood(mod, data, NULL);

      if (!isfinite(lnl) || !isfinite(logdet)) tr_free(mod->tree);
    } while (!isfinite(lnl) || !isfinite(logdet));

    mvnl = mmvn_log_dens(mmvn, points_x) - logdet;  /* include flow Jacobian */
    ll[i] = lnl;
    mvnll[i] = mvnl;
    logw[i] = lnl - mvnl;

    /* record shell & keep the tree */
    z2 = vec_inner_prod(points_z, points_z);
    shell[i] = get_region(quants, z2);
    regnum[shell[i]]++;
    lst_push_ptr(props, mod->tree);

    if (logw[i] > max_logw) max_logw = logw[i];
  }

  /* Weight normalization & diagnostics */
  /* global numerically-stable normalization */
  double *w = smalloc(nprop * sizeof(double));
  double sumw = 0.0;
  for (int i = 0; i < nprop; ++i) {
    double wi = exp(logw[i] - max_logw);
    w[i] = wi;
    sumw += wi;
  }
  if (sumw == 0.0 || !isfinite(sumw)) {
    /* underflow case: fall back to selecting top nsamples by logw */
    int *idx = smalloc(nprop * sizeof(int));
    for (int i = 0; i < nprop; ++i) idx[i] = i;
    /* partial sort by descending logw; just use simple insertion sort */
    for (int i = 1; i < nprop; ++i) {
      int j = i, t = idx[i];
      while (j > 0 && logw[idx[j-1]] < logw[t]) { idx[j] = idx[j-1]; j--; }
      idx[j] = t;
    }
    for (int k = 0; k < nsamples; ++k)
      lst_push_ptr(retval, lst_get_ptr(props, idx[k]));
    /* free the rest */
    for (int k = nsamples; k < nprop; ++k)
      tr_free(lst_get_ptr(props, idx[k]));
    sfree(idx);
    goto IS_CLEANUP;
  }
  for (int i = 0; i < nprop; ++i) w[i] /= sumw;

  /* ESS diagnostic */
  double ess_denom = 0.0;
  for (int i = 0; i < nprop; ++i) ess_denom += w[i]*w[i];
  double ESS = (ess_denom > 0.0) ? (1.0/ess_denom) : 0.0;

  /* TEMPORARY: print mass per shell for tuning */
  double *mass = smalloc(nreg * sizeof(double));
  for (int r = 0; r < nreg; ++r) mass[r] = 0.0;
  for (int i = 0; i < nprop; ++i) mass[shell[i]] += w[i];
  fprintf(stderr, "IS: shell weight masses: ");
  for (int r = 0; r < nreg; ++r) fprintf(stderr, "%d(%.3f) ", r, mass[r]);
  fprintf(stderr, " | ESS=%.1f / %d\n", ESS, nsamples);
  sfree(mass);

  /* resampling */
  int *idx = smalloc(nsamples * sizeof(int));
  double u0 = unif_rand() / nsamples;
  double c  = w[0];
  int j = 0;
  for (int k = 0; k < nsamples; ++k) {
    double u = u0 + ((double)k)/nsamples;
    while (u > c && j < nprop-1) { j++; c += w[j]; }
    idx[k] = j;
  }

  /* build retval */
  for (int k = 0; k < nsamples; ++k)
    lst_push_ptr(retval, lst_get_ptr(props, idx[k]));

  /* free trees not selected */
  unsigned char *mark = (unsigned char*)smalloc(nprop * sizeof(unsigned char));
  memset(mark, 0, nprop * sizeof(unsigned char));
  for (int k = 0; k < nsamples; ++k) mark[idx[k]] = 1;
  for (int i = 0; i < nprop; ++i)
    if (!mark[i]) tr_free(lst_get_ptr(props, i));

  if (logf != NULL) {
    /* average log-likelihood of selected (for rough comparability to RS) */
    double avelnl = 0.0;
    for (int k = 0; k < nsamples; ++k) avelnl += ll[idx[k]];
    avelnl /= (double)nsamples;
    fprintf(logf, "# IS from %d trees; ESS≈%.1f; avelnl: %f\n",
            nprop, ESS, avelnl);
  }

  /* cleanup */
  sfree(mark);
  sfree(idx);

IS_CLEANUP:
  /* common cleanup */
  lst_free(props);
  vec_free(points_x);
  vec_free(points_y);
  vec_free(points_z);
  vec_free(quants);
  sfree(logw);
  sfree(ll);
  sfree(mvnll);
  sfree(w);
  sfree(shell);
  sfree(regnum);

  return retval;
}
